{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef537be2",
   "metadata": {},
   "source": [
    "# AI Model Tracing\n",
    "\n",
    "This notebook demonstrates how to use tracing with the Azure AI Inference client library.\n",
    "It will guide you through setting up tracing, defining functions with tracing, and interacting with an AI model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd9daa",
   "metadata": {},
   "source": [
    "### ðŸ”§ Task: Configure Azure AI Inference Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbe322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage, UserMessage, CompletionsFinishReason,\n",
    "    ToolMessage, AssistantMessage, ChatCompletionsToolCall,\n",
    "    ChatCompletionsToolDefinition, FunctionDefinition\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from opentelemetry import trace\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "ai_project_endpoint=os.environ[\"AI_PROJECT_ENDPOINT\"]\n",
    "app_insights_connection_string=os.environ[\"APP_INSIGHTS_CONNECTION_STRING\"]\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "\n",
    "# Initialize the AIProjectClient\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=ai_project_endpoint,\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "# Enable Azure Monitor tracing\n",
    "configure_azure_monitor(connection_string=app_insights_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97c399",
   "metadata": {},
   "source": [
    "## Defining Functions with Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from opentelemetry.trace import get_tracer\n",
    "\n",
    "tracer = get_tracer(__name__)\n",
    "\n",
    "weather_api_key = os.environ.get(\"WEATHER_API_KEY\")\n",
    "\n",
    "@tracer.start_as_current_span(\"get_temperature\") \n",
    "def get_temperature(city: str) -> str:\n",
    "    span = trace.get_current_span()\n",
    "    span.set_attribute(\"requested_city\", city)\n",
    "    url = f\"http://api.weatherapi.com/v1/current.json?key={weather_api_key}&q={city}&aqi=no\"\n",
    "    try: \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        temp_c = data[\"current\"][\"temp_c\"]\n",
    "        return {\"temperature_celsius\": temp_c}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@tracer.start_as_current_span(\"get_weather\")\n",
    "def get_weather(city: str) -> str:\n",
    "    span = trace.get_current_span()\n",
    "    span.set_attribute(\"requested_city\", city)\n",
    "    url = f\"http://api.weatherapi.com/v1/current.json?key={weather_api_key}&q={city}&aqi=no\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        condition = data[\"current\"][\"condition\"][\"text\"]\n",
    "        return {\"condition\": condition}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36223ee2",
   "metadata": {},
   "source": [
    "## Chat Completion with Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71aa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_with_function_call(key, endpoint):\n",
    "    weather_description = ChatCompletionsToolDefinition(\n",
    "        function=FunctionDefinition(\n",
    "            name=\"get_weather\",\n",
    "            description=\"Returns description of the weather in the specified city\",\n",
    "            parameters={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    temperature_in_city = ChatCompletionsToolDefinition(\n",
    "        function=FunctionDefinition(\n",
    "            name=\"get_temperature\",\n",
    "            description=\"Returns the current temperature (in Celsius) for the specified city\",\n",
    "            parameters={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City name\"}\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    client = ChatCompletionsClient(\n",
    "        endpoint=endpoint, \n",
    "        credential=AzureKeyCredential(key),\n",
    "    )\n",
    "    messages = [\n",
    "        SystemMessage(content=\"\"\"\n",
    "        You are an AI assistant with access to various tools to enhance your capabilities. \n",
    "        Your primary goal is to assist the user efficiently and accurately by leveraging these tools when necessary. \n",
    "        Below are the tools you can use:\n",
    "        - `get_weather`: Returns the description of the weather in the specified city.\n",
    "        - `get_temperature`: Returns the current temperature for the specified city.\n",
    "        \"\"\"),\n",
    "        UserMessage(content=\"What is the weather and temperature in Bordeaux?\"),\n",
    "    ]\n",
    "    response = client.complete(\n",
    "        messages=messages, \n",
    "        tools=[weather_description, temperature_in_city],\n",
    "    )\n",
    "\n",
    "    if response.choices[0].finish_reason == CompletionsFinishReason.TOOL_CALLS:\n",
    "        messages.append(AssistantMessage(tool_calls=response.choices[0].message.tool_calls))\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            for tool_call in response.choices[0].message.tool_calls:\n",
    "                if isinstance(tool_call, ChatCompletionsToolCall):\n",
    "                    function_args = json.loads(tool_call.function.arguments.replace(\"'\", '\"'))\n",
    "                    print(f\"Calling function `{tool_call.function.name}` with arguments {function_args}\")\n",
    "                    function_response = globals()[tool_call.function.name](**function_args)\n",
    "                    print(f\"Function response = {function_response}\")\n",
    "                    messages.append(\n",
    "                        ToolMessage(\n",
    "                            content=str(function_response),\n",
    "                            tool_call_id=tool_call.id)\n",
    "                        )\n",
    "            response = client.complete(\n",
    "                messages=messages, \n",
    "                tools=[weather_description, temperature_in_city],\n",
    "                temperature=0.0,\n",
    "            )\n",
    "    print(f\"Model response = {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6ef8f",
   "metadata": {},
   "source": [
    "## Running the AI Model and Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7650f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
    "\n",
    "key=os.environ[\"AZURE_AI_CHAT_KEY\"]\n",
    "endpoint=os.environ[\"AZURE_AI_CHAT_ENDPOINT\"]\n",
    "\n",
    "AIInferenceInstrumentor().instrument()\n",
    "try:\n",
    "    chat_completion_with_function_call(key,endpoint)\n",
    "finally:\n",
    "    AIInferenceInstrumentor().uninstrument()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiops2envagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
