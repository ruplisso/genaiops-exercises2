{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-evaluation\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with RelevanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The response fully and accurately answers the question with all essential details, but does not provide any extra insights.', 'relevance_result': 'pass', 'relevance_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Evaluate a single query-response pair\n",
    "result = relevance_evaluator(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with CoherenceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The RESPONSE is coherent and effectively answers the QUERY with logical organization and clarity, though it is minimalistic.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator\n",
    "\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "\n",
    "result = coherence_evaluator(\n",
    "    query=\"What's the capital of France?\", \n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with FluencyEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fluency': 1.0, 'gpt_fluency': 1.0, 'fluency_reason': 'The RESPONSE is a single word without any grammatical structure or context, making it incomprehensible and indicative of minimal command of the language.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import FluencyEvaluator\n",
    "\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "\n",
    "result = fluency_evaluator(\n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with GroundednessEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 4.0, 'gpt_groundedness': 4.0, 'groundedness_reason': 'The response is accurate and directly answers the query but does not include all the details from the context, making it partially correct.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "\n",
    "result = groundedness_evaluator(\n",
    "    query=\"Who discovered penicillin?\",\n",
    "    context=\"Alexander Fleming discovered penicillin in 1928 while working at St. Mary's Hospital in London.\",\n",
    "    response=\"Alexander Fleming discovered penicillin in 1928.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code-based evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response_length': 13}\n"
     ]
    }
   ],
   "source": [
    "# Custom evaluator function to calculate response length\n",
    "def response_length_evaluator(response, **kwargs):\n",
    "    return {\"response_length\": len(response)}\n",
    "\n",
    "# Example usage\n",
    "result = response_length_evaluator(response=\"Hello, world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains_blocked_word': True}\n"
     ]
    }
   ],
   "source": [
    "# Custom class-based evaluator to check for blocked words\n",
    "class BlocklistEvaluator:\n",
    "    def __init__(self, blocklist):\n",
    "        self.blocklist = blocklist\n",
    "\n",
    "    def __call__(self, *, response: str, **kwargs):\n",
    "        contains_blocked_word = any(word in response for word in self.blocklist)\n",
    "        return {\"contains_blocked_word\": contains_blocked_word}\n",
    "    \n",
    "# Example usage\n",
    "blocklist_evaluator = BlocklistEvaluator(blocklist=[\"bad\", \"evil\", \"worst\"])\n",
    "result = blocklist_evaluator(response=\"This is the worst response ever!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt-based evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpfulness evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'helpfulness': 1.0, 'helpfulness_reason': 'The RESPONSE is entirely unhelpful as it does not address the philosophical question or provide any meaningful or relevant information based on the CONTEXT.'}\n"
     ]
    }
   ],
   "source": [
    "from helpfulness import HelpfulnessEvaluator\n",
    "\n",
    "helpfulness_evaluator = HelpfulnessEvaluator(model_config)\n",
    "\n",
    "helpfulness_score = helpfulness_evaluator(\n",
    "    query=\"What's the meaning of life?\", \n",
    "    context=\"Arthur Schopenhauer was the first to explicitly ask the question, in an essay entitled 'Character'.\", \n",
    "    response=\"The answer is 42.\"\n",
    ")\n",
    "print(helpfulness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON accuracy evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'json_schema': 0.5, 'json_schema_reason': 'The JSON output is partially correct but contains a critical error: the required \"companyName\" field is missing in the \"companyInfo\" object.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json_schema import JSONSchemaEvaluator\n",
    "\n",
    "# Load jsons/example.jsonl file here\n",
    "example_json_schema = json.load(open('jsons/example_schema.json', 'r'))\n",
    "\n",
    "# Example JSON object\n",
    "sample_json_data = json.load(open('jsons/poor_output.json', 'r'))\n",
    "\n",
    "json_schema_evaluator = JSONSchemaEvaluator(model_config)\n",
    "json_schema_score = json_schema_evaluator(json_output=sample_json_data, schema=example_json_schema)\n",
    "print(json_schema_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.ai.evaluation import evaluate, RetrievalEvaluator, RelevanceEvaluator\n",
    "from pprint import pprint\n",
    "from model_endpoint import ModelEndpoint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"RG_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Define your evaluators\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "retrieval_evaluator = RetrievalEvaluator(model_config)\n",
    "\n",
    "# Evaluate the dataset\n",
    "result = evaluate(\n",
    "    data=\"evaluation_dataset.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "    evaluators={\n",
    "        # Performance and quality evaluators (AI-assisted)\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        \"retrieval\": retrieval_evaluator,\n",
    "        # Custom evaluators (code and prompt based)\n",
    "        \"helpfulness\": helpfulness_evaluator,\n",
    "    },\n",
    "    evaluator_config={\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"retrieval\": {\n",
    "            \"column_mapping\": {\"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"helpfulness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "    },\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    output_path=\"./evaluation_results.json\",\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>outputs.response</th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.coherence.coherence</th>\n",
       "      <th>outputs.coherence.gpt_coherence</th>\n",
       "      <th>...</th>\n",
       "      <th>outputs.fluency.fluency_reason</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>outputs.retrieval.retrieval</th>\n",
       "      <th>outputs.retrieval.gpt_retrieval</th>\n",
       "      <th>outputs.retrieval.retrieval_reason</th>\n",
       "      <th>outputs.helpfulness.helpfulness</th>\n",
       "      <th>outputs.helpfulness.helpfulness_reason</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>On **July 28, 1914**, **World War I** official...</td>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>It involved multiple countries and lasted unti...</td>\n",
       "      <td>World War I</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully correct and complete, di...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The context is relevant to the query but is mi...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The first person to walk on the Moon was **Nei...</td>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The event occurred during the Apollo 11 missio...</td>\n",
       "      <td>Neil Armstrong</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully correct and complete, ad...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant as it mentio...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it answers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>The year 1776 is one of the most significant i...</td>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>A key document was signed declaring independen...</td>\n",
       "      <td>The Declaration of Independence</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is highly coherent, grammatically...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE thoroughly and accurately answers...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant, well-ranked, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it fully a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>The **Berlin Wall** fell in 1989, symbolizing ...</td>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>It divided a German city into East and West.</td>\n",
       "      <td>The Berlin Wall</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with prec...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant to the query...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The ancient city of **Pompeii** was buried by ...</td>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The city's ruins were rediscovered in the 18th...</td>\n",
       "      <td>Pompeii</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The RESPONSE is accurate and relevant to the Q...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The context does not provide relevant informat...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY and provi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>The British Prime Minister during most of Worl...</td>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>He is famous for his leadership and speeches, ...</td>\n",
       "      <td>Winston Churchill</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE is mostly correct and relevant bu...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant as it hints ...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>The ship that sank on its maiden voyage in 191...</td>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>It was deemed 'unsinkable' before it hit an ic...</td>\n",
       "      <td>RMS Titanic</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully correct and complete, di...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant as it hints ...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>Genghis Khan ruled the **Mongol Empire**, whic...</td>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>This empire became the largest contiguous land...</td>\n",
       "      <td>The Mongol Empire</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with accu...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, coherent, an...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with prec...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant to the query...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY and provi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The primary cause of the American Civil War wa...</td>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The conflict between the Northern and Southern...</td>\n",
       "      <td>Slavery</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is highly proficient, with clear,...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant to the query, d...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY, accura...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>The **Great Pyramid of Giza** was the ancient ...</td>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>It is the only one of the Seven Wonders of the...</td>\n",
       "      <td>The Great Pyramid of Giza</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-written, with clear and c...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY with prec...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant to the query...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully answers the QUERY and provi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       outputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                    outputs.response  \\\n",
       "0  On **July 28, 1914**, **World War I** official...   \n",
       "1  The first person to walk on the Moon was **Nei...   \n",
       "2  The year 1776 is one of the most significant i...   \n",
       "3  The **Berlin Wall** fell in 1989, symbolizing ...   \n",
       "4  The ancient city of **Pompeii** was buried by ...   \n",
       "5  The British Prime Minister during most of Worl...   \n",
       "6  The ship that sank on its maiden voyage in 191...   \n",
       "7  Genghis Khan ruled the **Mongol Empire**, whic...   \n",
       "8  The primary cause of the American Civil War wa...   \n",
       "9  The **Great Pyramid of Giza** was the ancient ...   \n",
       "\n",
       "                                        inputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  It involved multiple countries and lasted unti...   \n",
       "1  The event occurred during the Apollo 11 missio...   \n",
       "2  A key document was signed declaring independen...   \n",
       "3       It divided a German city into East and West.   \n",
       "4  The city's ruins were rediscovered in the 18th...   \n",
       "5  He is famous for his leadership and speeches, ...   \n",
       "6  It was deemed 'unsinkable' before it hit an ic...   \n",
       "7  This empire became the largest contiguous land...   \n",
       "8  The conflict between the Northern and Southern...   \n",
       "9  It is the only one of the Seven Wonders of the...   \n",
       "\n",
       "               inputs.ground_truth  outputs.relevance.relevance  \\\n",
       "0                      World War I                            5   \n",
       "1                   Neil Armstrong                            5   \n",
       "2  The Declaration of Independence                            5   \n",
       "3                  The Berlin Wall                            5   \n",
       "4                          Pompeii                            5   \n",
       "5                Winston Churchill                            5   \n",
       "6                      RMS Titanic                            5   \n",
       "7                The Mongol Empire                            5   \n",
       "8                          Slavery                            4   \n",
       "9        The Great Pyramid of Giza                            5   \n",
       "\n",
       "   outputs.relevance.gpt_relevance  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                5   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                5   \n",
       "7                                5   \n",
       "8                                4   \n",
       "9                                5   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The RESPONSE fully addresses the QUERY with ac...   \n",
       "1  The RESPONSE fully addresses the QUERY with ac...   \n",
       "2  The RESPONSE fully addresses the QUERY with ac...   \n",
       "3  The RESPONSE fully answers the QUERY with accu...   \n",
       "4  The RESPONSE fully answers the QUERY with accu...   \n",
       "5  The RESPONSE fully answers the QUERY with accu...   \n",
       "6  The RESPONSE fully answers the QUERY with accu...   \n",
       "7  The RESPONSE fully answers the QUERY with accu...   \n",
       "8  The RESPONSE fully addresses the QUERY with ac...   \n",
       "9  The RESPONSE fully addresses the QUERY with ac...   \n",
       "\n",
       "   outputs.coherence.coherence  outputs.coherence.gpt_coherence  ...  \\\n",
       "0                            5                                5  ...   \n",
       "1                            4                                4  ...   \n",
       "2                            5                                5  ...   \n",
       "3                            5                                5  ...   \n",
       "4                            4                                4  ...   \n",
       "5                            5                                5  ...   \n",
       "6                            4                                4  ...   \n",
       "7                            5                                5  ...   \n",
       "8                            4                                4  ...   \n",
       "9                            4                                4  ...   \n",
       "\n",
       "                      outputs.fluency.fluency_reason  \\\n",
       "0  The RESPONSE is well-articulated, coherent, an...   \n",
       "1  The RESPONSE is well-articulated, coherent, an...   \n",
       "2  The RESPONSE is highly coherent, grammatically...   \n",
       "3  The RESPONSE is well-articulated, coherent, an...   \n",
       "4  The RESPONSE is well-articulated, coherent, an...   \n",
       "5  The RESPONSE is well-articulated, coherent, an...   \n",
       "6  The RESPONSE is well-articulated, coherent, an...   \n",
       "7  The RESPONSE is well-articulated, coherent, an...   \n",
       "8  The RESPONSE is highly proficient, with clear,...   \n",
       "9  The RESPONSE is well-written, with clear and c...   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  5                                      5   \n",
       "1                                  5                                      5   \n",
       "2                                  5                                      5   \n",
       "3                                  5                                      5   \n",
       "4                                  2                                      2   \n",
       "5                                  4                                      4   \n",
       "6                                  5                                      5   \n",
       "7                                  5                                      5   \n",
       "8                                  5                                      5   \n",
       "9                                  5                                      5   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  \\\n",
       "0  The RESPONSE is fully correct and complete, di...   \n",
       "1  The RESPONSE is fully correct and complete, ad...   \n",
       "2  The RESPONSE thoroughly and accurately answers...   \n",
       "3  The RESPONSE fully answers the QUERY with prec...   \n",
       "4  The RESPONSE is accurate and relevant to the Q...   \n",
       "5  The RESPONSE is mostly correct and relevant bu...   \n",
       "6  The RESPONSE is fully correct and complete, di...   \n",
       "7  The RESPONSE fully answers the QUERY with prec...   \n",
       "8  The RESPONSE fully addresses the QUERY with pr...   \n",
       "9  The RESPONSE fully answers the QUERY with prec...   \n",
       "\n",
       "   outputs.retrieval.retrieval  outputs.retrieval.gpt_retrieval  \\\n",
       "0                            3                                3   \n",
       "1                            2                                2   \n",
       "2                            5                                5   \n",
       "3                            2                                2   \n",
       "4                            1                                1   \n",
       "5                            2                                2   \n",
       "6                            2                                2   \n",
       "7                            2                                2   \n",
       "8                            5                                5   \n",
       "9                            2                                2   \n",
       "\n",
       "                  outputs.retrieval.retrieval_reason  \\\n",
       "0  The context is relevant to the query but is mi...   \n",
       "1  The context is partially relevant as it mentio...   \n",
       "2  The context is highly relevant, well-ranked, a...   \n",
       "3  The context is partially relevant to the query...   \n",
       "4  The context does not provide relevant informat...   \n",
       "5  The context is partially relevant as it hints ...   \n",
       "6  The context is partially relevant as it hints ...   \n",
       "7  The context is partially relevant to the query...   \n",
       "8  The context is highly relevant to the query, d...   \n",
       "9  The context is partially relevant to the query...   \n",
       "\n",
       "   outputs.helpfulness.helpfulness  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                5   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                5   \n",
       "7                                5   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "              outputs.helpfulness.helpfulness_reason line_number  \n",
       "0  The RESPONSE fully answers the QUERY with accu...           0  \n",
       "1  The RESPONSE is entirely helpful as it answers...           1  \n",
       "2  The RESPONSE is entirely helpful as it fully a...           2  \n",
       "3  The RESPONSE fully answers the QUERY with accu...           3  \n",
       "4  The RESPONSE fully answers the QUERY and provi...           4  \n",
       "5  The RESPONSE fully answers the QUERY with accu...           5  \n",
       "6  The RESPONSE is entirely helpful as it accurat...           6  \n",
       "7  The RESPONSE fully answers the QUERY and provi...           7  \n",
       "8  The RESPONSE fully addresses the QUERY, accura...           8  \n",
       "9  The RESPONSE fully answers the QUERY and provi...           9  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result[\"rows\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-evaluation in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: promptflow-devkit>=1.17.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: promptflow-core>=1.17.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (2.9.0)\n",
      "Requirement already satisfied: azure-identity>=1.16.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.21.0)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.32.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (12.24.0)\n",
      "Requirement already satisfied: httpx>=0.25.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (2.2.3)\n",
      "Requirement already satisfied: openai>=1.78.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.79.0)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (0.18.10)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (0.7.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (6.0.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.18.3)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.12.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (44.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-storage-blob>=12.10.0->azure-ai-evaluation) (0.6.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2>=3.1.6->azure-ai-evaluation) (2.1.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (4.67.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (2.10.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2024.1)\n",
      "Requirement already satisfied: docstring_parser in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.16)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.115.6)\n",
      "Requirement already satisfied: filetype>=1.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (3.0.3)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (4.23.0)\n",
      "Requirement already satisfied: promptflow-tracing==1.17.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (5.9.8)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.8.0)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.5.1)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.0b32)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.16.1)\n",
      "Requirement already satisfied: flask-cors<6.0.0,>=5.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.0)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.43)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (24.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.21.3)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: pillow<11.1.0,>=10.1.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.3.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.0.7)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.1)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (306)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (2.0.31)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.7.3)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.8)\n",
      "Requirement already satisfied: fixedint==0.1.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-api~=1.26 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.41.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.0.6)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: aniso8601>=0.82 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (9.0.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (6.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (4.0.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.18.1)\n",
      "Requirement already satisfied: jaraco.classes in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.4.0)\n",
      "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.2.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (23.2)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity>=1.16.0->azure-ai-evaluation) (2.10.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.2.15)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.28.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.22)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.1)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api~=1.26->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.2.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.49b2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.26->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.21.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\alevret\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\alevret\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\alevret\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg@3': 0.31075932533963707,\n",
       " 'xdcg@3': 39.285714285714285,\n",
       " 'fidelity': 0.39285714285714285,\n",
       " 'top1_relevance': 2,\n",
       " 'top3_max_relevance': 3,\n",
       " 'holes': 2,\n",
       " 'holes_ratio': 0.4,\n",
       " 'total_retrieved_documents': 5,\n",
       " 'total_ground_truth_documents': 5,\n",
       " 'ndcg@3_result': 'fail',\n",
       " 'ndcg@3_threshold': 0.5,\n",
       " 'ndcg@3_higher_is_better': True,\n",
       " 'xdcg@3_result': 'fail',\n",
       " 'xdcg@3_threshold': 50.0,\n",
       " 'xdcg@3_higher_is_better': True,\n",
       " 'fidelity_result': 'fail',\n",
       " 'fidelity_threshold': 0.5,\n",
       " 'fidelity_higher_is_better': True,\n",
       " 'top1_relevance_result': 'fail',\n",
       " 'top1_relevance_threshold': 50.0,\n",
       " 'top1_relevance_higher_is_better': True,\n",
       " 'top3_max_relevance_result': 'fail',\n",
       " 'top3_max_relevance_threshold': 50.0,\n",
       " 'top3_max_relevance_higher_is_better': True,\n",
       " 'holes_result': 'fail',\n",
       " 'holes_threshold': 0,\n",
       " 'holes_higher_is_better': False,\n",
       " 'holes_ratio_result': 'fail',\n",
       " 'holes_ratio_threshold': 0,\n",
       " 'holes_ratio_higher_is_better': False,\n",
       " 'total_retrieved_documents_result': 'fail',\n",
       " 'total_retrieved_documents_threshold': 50,\n",
       " 'total_retrieved_documents_higher_is_better': True,\n",
       " 'total_ground_truth_documents_result': 'fail',\n",
       " 'total_ground_truth_documents_threshold': 50,\n",
       " 'total_ground_truth_documents_higher_is_better': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.evaluation import DocumentRetrievalEvaluator\n",
    "\n",
    "# these query_relevance_label are given by your human- or LLM-judges.\n",
    "retrieval_ground_truth = [\n",
    "    {\n",
    "        \"document_id\": \"1\",\n",
    "        \"query_relevance_label\": 4\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"2\",\n",
    "        \"query_relevance_label\": 2\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"3\",\n",
    "        \"query_relevance_label\": 3\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"4\",\n",
    "        \"query_relevance_label\": 1\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"5\",\n",
    "        \"query_relevance_label\": 0\n",
    "    },\n",
    "]\n",
    "# the min and max of the label scores are inputs to document retrieval evaluator\n",
    "ground_truth_label_min = 0\n",
    "ground_truth_label_max = 4\n",
    "\n",
    "# these relevance scores come from your search retrieval system\n",
    "retrieved_documents = [\n",
    "    {\n",
    "        \"document_id\": \"2\",\n",
    "        \"relevance_score\": 45.1\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"6\",\n",
    "        \"relevance_score\": 35.8\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"3\",\n",
    "        \"relevance_score\": 29.2\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"5\",\n",
    "        \"relevance_score\": 25.4\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"7\",\n",
    "        \"relevance_score\": 18.8\n",
    "    },\n",
    "]\n",
    "\n",
    "document_retrieval_evaluator = DocumentRetrievalEvaluator(\n",
    "    ground_truth_label_min=ground_truth_label_min, \n",
    "    ground_truth_label_max=ground_truth_label_max,\n",
    "    ndcg_threshold = 0.5,\n",
    "    xdcg_threshold = 50.0,\n",
    "    fidelity_threshold = 0.5,\n",
    "    top1_relevance_threshold = 50.0,\n",
    "    top3_max_relevance_threshold = 50.0,\n",
    "    total_retrieved_documents_threshold = 50,\n",
    "    total_ground_truth_documents_threshold = 50\n",
    ")\n",
    "document_retrieval_evaluator(retrieval_ground_truth=retrieval_ground_truth, retrieved_documents=retrieved_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiops2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
