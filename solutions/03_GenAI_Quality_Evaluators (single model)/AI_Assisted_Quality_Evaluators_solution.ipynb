{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-evaluation\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with RelevanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The response accurately and completely answers the query by providing the correct capital of France, which is Paris.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Configure the AOAI model that will be used for evaluation (AI-as-a-judge)\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}\n",
    "\n",
    "# Initialize the Relevance evaluator\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Evaluate a single query-response pair\n",
    "result = relevance_evaluator(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with CoherenceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The response is coherent because it directly and correctly answers the query without any unnecessary information. The simplicity of the question allows for a straightforward response, which is provided here.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator\n",
    "\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "\n",
    "result = coherence_evaluator(\n",
    "    query=\"What's the capital of France?\", \n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with FluencyEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fluency': 1.0, 'gpt_fluency': 1.0, 'fluency_reason': 'The RESPONSE is a single word and does not demonstrate any fluency in terms of sentence structure, grammar, or vocabulary. It is largely incomprehensible as it does not convey any meaningful message.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import FluencyEvaluator\n",
    "\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "\n",
    "result = fluency_evaluator(\n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The response accurately and completely answers the query based on the context provided, without introducing any errors or unrelated information.'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "\n",
    "result = groundedness_evaluator(\n",
    "    query=\"Who discovered penicillin?\",\n",
    "    context=\"Alexander Fleming discovered penicillin in 1928 while working at St. Mary's Hospital in London.\",\n",
    "    response=\"Alexander Fleming discovered penicillin in 1928.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code-based evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response_length': 13}\n"
     ]
    }
   ],
   "source": [
    "# Custom evaluator function to calculate response length\n",
    "def response_length_evaluator(response, **kwargs):\n",
    "    return {\"response_length\": len(response)}\n",
    "\n",
    "# Example usage\n",
    "result = response_length_evaluator(response=\"Hello, world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains_blocked_word': True}\n"
     ]
    }
   ],
   "source": [
    "# Custom class-based evaluator to check for blocked words\n",
    "class BlocklistEvaluator:\n",
    "    def __init__(self, blocklist):\n",
    "        self.blocklist = blocklist\n",
    "\n",
    "    def __call__(self, *, response: str, **kwargs):\n",
    "        contains_blocked_word = any(word in response for word in self.blocklist)\n",
    "        return {\"contains_blocked_word\": contains_blocked_word}\n",
    "    \n",
    "# Example usage\n",
    "blocklist_evaluator = BlocklistEvaluator(blocklist=[\"bad\", \"evil\", \"worst\"])\n",
    "result = blocklist_evaluator(response=\"This is the worst response ever!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt-based evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpfulness evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'helpfulness': 1.0, 'helpfulness_reason': 'The RESPONSE does not address the philosophical nature of the QUERY or relate to the CONTEXT, making it unhelpful.'}\n"
     ]
    }
   ],
   "source": [
    "from helpfulness import HelpfulnessEvaluator\n",
    "\n",
    "helpfulness_evaluator = HelpfulnessEvaluator(model_config)\n",
    "\n",
    "helpfulness_score = helpfulness_evaluator(\n",
    "    query=\"What's the meaning of life?\", \n",
    "    context=\"Arthur Schopenhauer was the first to explicitly ask the question, in an essay entitled 'Character'.\", \n",
    "    response=\"The answer is 42.\"\n",
    ")\n",
    "print(helpfulness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON accuracy evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'json_schema': 0.5, 'json_schema_reason': 'The JSON output is mostly compliant with the schema, but it is missing the required \"companyName\" field in the \"companyInfo\" object, which affects its completeness.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json_schema import JSONSchemaEvaluator\n",
    "\n",
    "# Load jsons/example.jsonl file here\n",
    "example_json_schema = json.load(open('jsons/example_schema.json', 'r'))\n",
    "\n",
    "# Example JSON object\n",
    "sample_json_data = json.load(open('jsons/poor_output.json', 'r'))\n",
    "\n",
    "json_schema_evaluator = JSONSchemaEvaluator(model_config)\n",
    "json_schema_score = json_schema_evaluator(json_output=sample_json_data, schema=example_json_schema)\n",
    "print(json_schema_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.ai.evaluation import evaluate, RetrievalEvaluator\n",
    "from pprint import pprint\n",
    "from model_endpoint import ModelEndpoint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"RG_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Define your evaluators\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "retrieval_evaluator = RetrievalEvaluator(model_config)\n",
    "\n",
    "# Evaluate the dataset\n",
    "result = evaluate(\n",
    "    data=\"evaluation_dataset.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "    evaluators={\n",
    "        # Performance and quality evaluators (AI-assisted)\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        \"retrieval\": retrieval_evaluator,\n",
    "        # Custom evaluators (code and prompt based)\n",
    "        \"helpfulness\": helpfulness_evaluator,\n",
    "    },\n",
    "    evaluator_config={\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"retrieval\": {\n",
    "            \"column_mapping\": {\"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"helpfulness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "    },\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    output_path=\"./evaluation_results.json\",\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>outputs.response</th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.coherence.coherence</th>\n",
       "      <th>outputs.coherence.gpt_coherence</th>\n",
       "      <th>...</th>\n",
       "      <th>outputs.fluency.fluency_reason</th>\n",
       "      <th>outputs.groundedness.groundedness</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>outputs.groundedness.groundedness_reason</th>\n",
       "      <th>outputs.retrieval.retrieval</th>\n",
       "      <th>outputs.retrieval.gpt_retrieval</th>\n",
       "      <th>outputs.retrieval.retrieval_reason</th>\n",
       "      <th>outputs.helpfulness.helpfulness</th>\n",
       "      <th>outputs.helpfulness.helpfulness_reason</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>World War I began on July 28, 1914, when Austr...</td>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>It involved multiple countries and lasted unti...</td>\n",
       "      <td>World War I</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely address...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated with good con...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant to the query, p...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The first person to walk on the moon was Neil ...</td>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The event occurred during the Apollo 11 missio...</td>\n",
       "      <td>Neil Armstrong</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response not only answers the query accura...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, with good co...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant to the query...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it correctly ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>The year 1776 is highly significant in America...</td>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>A key document was signed declaring independen...</td>\n",
       "      <td>The Declaration of Independence</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE demonstrates a strong command of ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully grounded in the CONTEXT ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context directly addresses the query by me...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it fully a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>The Berlin Wall fell in 1989, symbolizing the ...</td>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>It divided a German city into East and West.</td>\n",
       "      <td>The Berlin Wall</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is clear, grammatically correct, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant and directly ad...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The ancient city of Pompeii was buried by the ...</td>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The city's ruins were rediscovered in the 18th...</td>\n",
       "      <td>Pompeii</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response not only answers the query accura...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is clear and grammatically correc...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant as it relate...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE accurately and completely answers...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>During World War II, the British Prime Ministe...</td>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>He is famous for his leadership and speeches, ...</td>\n",
       "      <td>Winston Churchill</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is accurate, complete, and provid...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The response is well-structured, coherent, and...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully grounded in the context ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant to the query...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>The ship that sank on its maiden voyage in 191...</td>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>It was deemed 'unsinkable' before it hit an ic...</td>\n",
       "      <td>RMS Titanic</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The response is clear and grammatically correc...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully correct and complete, di...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The context is relevant to the query as it des...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is fully helpful as it accurately...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>Genghis Khan ruled the Mongol Empire. He found...</td>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>This empire became the largest contiguous land...</td>\n",
       "      <td>The Mongol Empire</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response not only accurately and completel...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The response is well-articulated, with good co...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely answers...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant and well-ranked...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE fully addresses the QUERY by nami...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The primary cause of the American Civil War wa...</td>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The conflict between the Northern and Southern...</td>\n",
       "      <td>Slavery</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully addresses the query with ac...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, with good co...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately and completely address...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context directly addresses the query by me...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>The Great Pyramid of Giza, located in Egypt, s...</td>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>It is the only one of the Seven Wonders of the...</td>\n",
       "      <td>The Great Pyramid of Giza</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE accurately and completely address...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>The RESPONSE is well-articulated, with good co...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response accurately identifies the Great P...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The context is relevant to the query as it ind...</td>\n",
       "      <td>5</td>\n",
       "      <td>The RESPONSE is entirely helpful as it accurat...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       outputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                    outputs.response  \\\n",
       "0  World War I began on July 28, 1914, when Austr...   \n",
       "1  The first person to walk on the moon was Neil ...   \n",
       "2  The year 1776 is highly significant in America...   \n",
       "3  The Berlin Wall fell in 1989, symbolizing the ...   \n",
       "4  The ancient city of Pompeii was buried by the ...   \n",
       "5  During World War II, the British Prime Ministe...   \n",
       "6  The ship that sank on its maiden voyage in 191...   \n",
       "7  Genghis Khan ruled the Mongol Empire. He found...   \n",
       "8  The primary cause of the American Civil War wa...   \n",
       "9  The Great Pyramid of Giza, located in Egypt, s...   \n",
       "\n",
       "                                        inputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  It involved multiple countries and lasted unti...   \n",
       "1  The event occurred during the Apollo 11 missio...   \n",
       "2  A key document was signed declaring independen...   \n",
       "3       It divided a German city into East and West.   \n",
       "4  The city's ruins were rediscovered in the 18th...   \n",
       "5  He is famous for his leadership and speeches, ...   \n",
       "6  It was deemed 'unsinkable' before it hit an ic...   \n",
       "7  This empire became the largest contiguous land...   \n",
       "8  The conflict between the Northern and Southern...   \n",
       "9  It is the only one of the Seven Wonders of the...   \n",
       "\n",
       "               inputs.ground_truth  outputs.relevance.relevance  \\\n",
       "0                      World War I                            5   \n",
       "1                   Neil Armstrong                            5   \n",
       "2  The Declaration of Independence                            5   \n",
       "3                  The Berlin Wall                            4   \n",
       "4                          Pompeii                            5   \n",
       "5                Winston Churchill                            5   \n",
       "6                      RMS Titanic                            4   \n",
       "7                The Mongol Empire                            5   \n",
       "8                          Slavery                            5   \n",
       "9        The Great Pyramid of Giza                            5   \n",
       "\n",
       "   outputs.relevance.gpt_relevance  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                4   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                4   \n",
       "7                                5   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The response accurately and completely address...   \n",
       "1  The response not only answers the query accura...   \n",
       "2  The response fully addresses the query with ac...   \n",
       "3  The RESPONSE fully addresses the QUERY with ac...   \n",
       "4  The response not only answers the query accura...   \n",
       "5  The response is accurate, complete, and provid...   \n",
       "6  The response accurately and completely answers...   \n",
       "7  The response not only accurately and completel...   \n",
       "8  The response fully addresses the query with ac...   \n",
       "9  The RESPONSE accurately and completely address...   \n",
       "\n",
       "   outputs.coherence.coherence  outputs.coherence.gpt_coherence  ...  \\\n",
       "0                            4                                4  ...   \n",
       "1                            4                                4  ...   \n",
       "2                            4                                4  ...   \n",
       "3                            4                                4  ...   \n",
       "4                            4                                4  ...   \n",
       "5                            4                                4  ...   \n",
       "6                            4                                4  ...   \n",
       "7                            4                                4  ...   \n",
       "8                            4                                4  ...   \n",
       "9                            4                                4  ...   \n",
       "\n",
       "                      outputs.fluency.fluency_reason  \\\n",
       "0  The RESPONSE is well-articulated with good con...   \n",
       "1  The RESPONSE is well-articulated, with good co...   \n",
       "2  The RESPONSE demonstrates a strong command of ...   \n",
       "3  The RESPONSE is clear, grammatically correct, ...   \n",
       "4  The RESPONSE is clear and grammatically correc...   \n",
       "5  The response is well-structured, coherent, and...   \n",
       "6  The response is clear and grammatically correc...   \n",
       "7  The response is well-articulated, with good co...   \n",
       "8  The RESPONSE is well-articulated, with good co...   \n",
       "9  The RESPONSE is well-articulated, with good co...   \n",
       "\n",
       "   outputs.groundedness.groundedness  outputs.groundedness.gpt_groundedness  \\\n",
       "0                                  5                                      5   \n",
       "1                                  5                                      5   \n",
       "2                                  5                                      5   \n",
       "3                                  5                                      5   \n",
       "4                                  3                                      3   \n",
       "5                                  5                                      5   \n",
       "6                                  5                                      5   \n",
       "7                                  5                                      5   \n",
       "8                                  5                                      5   \n",
       "9                                  5                                      5   \n",
       "\n",
       "            outputs.groundedness.groundedness_reason  \\\n",
       "0  The response accurately and completely answers...   \n",
       "1  The response is fully correct and complete, di...   \n",
       "2  The RESPONSE is fully grounded in the CONTEXT ...   \n",
       "3  The response is fully correct and complete, di...   \n",
       "4  The response accurately and completely answers...   \n",
       "5  The response is fully grounded in the context ...   \n",
       "6  The response is fully correct and complete, di...   \n",
       "7  The response accurately and completely answers...   \n",
       "8  The response accurately and completely address...   \n",
       "9  The response accurately identifies the Great P...   \n",
       "\n",
       "   outputs.retrieval.retrieval  outputs.retrieval.gpt_retrieval  \\\n",
       "0                            5                                5   \n",
       "1                            2                                2   \n",
       "2                            5                                5   \n",
       "3                            5                                5   \n",
       "4                            2                                2   \n",
       "5                            2                                2   \n",
       "6                            3                                3   \n",
       "7                            5                                5   \n",
       "8                            5                                5   \n",
       "9                            3                                3   \n",
       "\n",
       "                  outputs.retrieval.retrieval_reason  \\\n",
       "0  The context is highly relevant to the query, p...   \n",
       "1  The context is partially relevant to the query...   \n",
       "2  The context directly addresses the query by me...   \n",
       "3  The context is highly relevant and directly ad...   \n",
       "4  The context is partially relevant as it relate...   \n",
       "5  The context is partially relevant to the query...   \n",
       "6  The context is relevant to the query as it des...   \n",
       "7  The context is highly relevant and well-ranked...   \n",
       "8  The context directly addresses the query by me...   \n",
       "9  The context is relevant to the query as it ind...   \n",
       "\n",
       "   outputs.helpfulness.helpfulness  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                5   \n",
       "4                                5   \n",
       "5                                5   \n",
       "6                                5   \n",
       "7                                5   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "              outputs.helpfulness.helpfulness_reason line_number  \n",
       "0  The RESPONSE is fully helpful as it accurately...           0  \n",
       "1  The RESPONSE is fully helpful as it correctly ...           1  \n",
       "2  The RESPONSE is entirely helpful as it fully a...           2  \n",
       "3  The RESPONSE is fully helpful as it accurately...           3  \n",
       "4  The RESPONSE accurately and completely answers...           4  \n",
       "5  The RESPONSE is entirely helpful as it accurat...           5  \n",
       "6  The RESPONSE is fully helpful as it accurately...           6  \n",
       "7  The RESPONSE fully addresses the QUERY by nami...           7  \n",
       "8  The RESPONSE is entirely helpful as it accurat...           8  \n",
       "9  The RESPONSE is entirely helpful as it accurat...           9  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result[\"rows\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
