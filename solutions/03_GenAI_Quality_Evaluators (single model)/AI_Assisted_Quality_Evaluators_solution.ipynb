{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-ai-evaluation\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with RelevanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The response fully and accurately answers the question with all essential details, but does not provide any extra insights.', 'relevance_result': 'pass', 'relevance_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import RelevanceEvaluator\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "\n",
    "# Evaluate a single query-response pair\n",
    "result = relevance_evaluator(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with CoherenceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coherence': 4.0, 'gpt_coherence': 4.0, 'coherence_reason': 'The response is fully coherent for the type of question asked, providing a direct and logically connected answer.', 'coherence_result': 'pass', 'coherence_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import CoherenceEvaluator\n",
    "\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "\n",
    "result = coherence_evaluator(\n",
    "    query=\"What's the capital of France?\", \n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with FluencyEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fluency': 1.0, 'gpt_fluency': 1.0, 'fluency_reason': 'The response is a single word and does not demonstrate any command of language, sentence structure, or coherence.', 'fluency_result': 'fail', 'fluency_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import FluencyEvaluator\n",
    "\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "\n",
    "result = fluency_evaluator(\n",
    "    response=\"Paris.\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Response Quality with GroundednessEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The response is fully correct and complete, directly addressing the query with all relevant details from the context.', 'groundedness_result': 'pass', 'groundedness_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "\n",
    "result = groundedness_evaluator(\n",
    "    query=\"Who discovered penicillin?\",\n",
    "    context=\"Alexander Fleming discovered penicillin in 1928 while working at St. Mary's Hospital in London.\",\n",
    "    response=\"Alexander Fleming discovered penicillin in 1928.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code-based evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response_length': 13}\n"
     ]
    }
   ],
   "source": [
    "# Custom evaluator function to calculate response length\n",
    "def response_length_evaluator(response, **kwargs):\n",
    "    return {\"response_length\": len(response)}\n",
    "\n",
    "# Example usage\n",
    "result = response_length_evaluator(response=\"Hello, world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-based evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains_blocked_word': True}\n"
     ]
    }
   ],
   "source": [
    "# Custom class-based evaluator to check for blocked words\n",
    "class BlocklistEvaluator:\n",
    "    def __init__(self, blocklist):\n",
    "        self.blocklist = blocklist\n",
    "\n",
    "    def __call__(self, *, response: str, **kwargs):\n",
    "        contains_blocked_word = any(word in response for word in self.blocklist)\n",
    "        return {\"contains_blocked_word\": contains_blocked_word}\n",
    "    \n",
    "# Example usage\n",
    "blocklist_evaluator = BlocklistEvaluator(blocklist=[\"bad\", \"evil\", \"worst\"])\n",
    "result = blocklist_evaluator(response=\"This is the worst response ever!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt-based evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpfulness evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'helpfulness': 1.0, 'helpfulness_reason': \"The response is entirely unhelpful, as it does not address the user's question in a meaningful or informative way and ignores the context provided.\"}\n"
     ]
    }
   ],
   "source": [
    "from helpfulness import HelpfulnessEvaluator\n",
    "\n",
    "helpfulness_evaluator = HelpfulnessEvaluator(model_config)\n",
    "\n",
    "helpfulness_score = helpfulness_evaluator(\n",
    "    query=\"What's the meaning of life?\", \n",
    "    context=\"Arthur Schopenhauer was the first to explicitly ask the question, in an essay entitled 'Character'.\", \n",
    "    response=\"The answer is 42.\"\n",
    ")\n",
    "print(helpfulness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON accuracy evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'json_schema': 0.5, 'json_schema_reason': 'The JSON output is almost fully compliant with the schema, but it is missing the required \"companyName\" field in the \"companyInfo\" object. All other fields, types, and structures are correct.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json_schema import JSONSchemaEvaluator\n",
    "\n",
    "# Load jsons/example.jsonl file here\n",
    "example_json_schema = json.load(open('jsons/example_schema.json', 'r'))\n",
    "\n",
    "# Example JSON object\n",
    "sample_json_data = json.load(open('jsons/poor_output.json', 'r'))\n",
    "\n",
    "json_schema_evaluator = JSONSchemaEvaluator(model_config)\n",
    "json_schema_score = json_schema_evaluator(json_output=sample_json_data, schema=example_json_schema)\n",
    "print(json_schema_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.ai.evaluation import evaluate, RetrievalEvaluator\n",
    "from pprint import pprint\n",
    "from model_endpoint import ModelEndpoint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"RG_NAME\"),\n",
    "    \"project_name\": os.environ.get(\"PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Define your evaluators\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "retrieval_evaluator = RetrievalEvaluator(model_config)\n",
    "\n",
    "# Evaluate the dataset\n",
    "result = evaluate(\n",
    "    data=\"evaluation_dataset.jsonl\",\n",
    "    target=ModelEndpoint(model_config),\n",
    "    evaluators={\n",
    "        # Performance and quality evaluators (AI-assisted)\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        \"retrieval\": retrieval_evaluator,\n",
    "        # Custom evaluators (code and prompt based)\n",
    "        \"helpfulness\": helpfulness_evaluator,\n",
    "    },\n",
    "    evaluator_config={\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"retrieval\": {\n",
    "            \"column_mapping\": {\"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"helpfulness\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "    },\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    output_path=\"./evaluation_results.json\",\n",
    ")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>outputs.response</th>\n",
       "      <th>inputs.query</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.ground_truth</th>\n",
       "      <th>outputs.relevance.relevance</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.relevance.relevance_reason</th>\n",
       "      <th>outputs.relevance.relevance_result</th>\n",
       "      <th>outputs.relevance.relevance_threshold</th>\n",
       "      <th>...</th>\n",
       "      <th>outputs.groundedness.groundedness_result</th>\n",
       "      <th>outputs.groundedness.groundedness_threshold</th>\n",
       "      <th>outputs.retrieval.retrieval</th>\n",
       "      <th>outputs.retrieval.gpt_retrieval</th>\n",
       "      <th>outputs.retrieval.retrieval_reason</th>\n",
       "      <th>outputs.retrieval.retrieval_result</th>\n",
       "      <th>outputs.retrieval.retrieval_threshold</th>\n",
       "      <th>outputs.helpfulness.helpfulness</th>\n",
       "      <th>outputs.helpfulness.helpfulness_reason</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>The event that started on **July 28, 1914** wa...</td>\n",
       "      <td>What event started on July 28, 1914?</td>\n",
       "      <td>It involved multiple countries and lasted unti...</td>\n",
       "      <td>World War I</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully accurate, complete, and ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant because it g...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully answers the question, accur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The first person to walk on the moon was **Nei...</td>\n",
       "      <td>Who was the first person to walk on the moon?</td>\n",
       "      <td>The event occurred during the Apollo 11 missio...</td>\n",
       "      <td>Neil Armstrong</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is accurate, complete, and includ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant because it r...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully accurate, complete, and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>The year **1776** is highly significant in Ame...</td>\n",
       "      <td>What was the significance of the year 1776 in ...</td>\n",
       "      <td>A key document was signed declaring independen...</td>\n",
       "      <td>The Declaration of Independence</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is not only complete and accurate...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant, directly answe...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully helpful, providing a com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>The **Berlin Wall** fell in 1989, symbolizing ...</td>\n",
       "      <td>Which wall fell in 1989, symbolizing the end o...</td>\n",
       "      <td>It divided a German city into East and West.</td>\n",
       "      <td>The Berlin Wall</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response fully and accurately answers the ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is partially relevant as it hints ...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is entirely helpful, directly ans...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The ancient city buried by the eruption of Mou...</td>\n",
       "      <td>What ancient city was buried by the eruption o...</td>\n",
       "      <td>The city's ruins were rediscovered in the 18th...</td>\n",
       "      <td>Pompeii</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response is accurate and fully answers the...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The context does not provide relevant informat...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully and accurately answers the ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>The British Prime Minister during most of Worl...</td>\n",
       "      <td>Who was the British Prime Minister during Worl...</td>\n",
       "      <td>He is famous for his leadership and speeches, ...</td>\n",
       "      <td>Winston Churchill</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is accurate, complete, and includ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The context does not provide the name of the B...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is entirely helpful, accurately n...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>The name of the ship that sank on its maiden v...</td>\n",
       "      <td>What was the name of the ship that sank on its...</td>\n",
       "      <td>It was deemed 'unsinkable' before it hit an ic...</td>\n",
       "      <td>RMS Titanic</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response fully and accurately answers the ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>The context is somewhat relevant but does not ...</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is entirely helpful, directly ans...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>Genghis Khan ruled the **Mongol Empire**.</td>\n",
       "      <td>Which empire was ruled by Genghis Khan?</td>\n",
       "      <td>This empire became the largest contiguous land...</td>\n",
       "      <td>The Mongol Empire</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>The response fully and accurately answers the ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant to the query, d...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully and accurately answers the ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The primary cause of the American Civil War wa...</td>\n",
       "      <td>What was the primary cause of the American Civ...</td>\n",
       "      <td>The conflict between the Northern and Southern...</td>\n",
       "      <td>Slavery</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully answers the question and pr...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant, directly addre...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully answers the question, accur...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>The **Great Pyramid of Giza** was the ancient ...</td>\n",
       "      <td>Which ancient wonder was located in Egypt and ...</td>\n",
       "      <td>It is the only one of the Seven Wonders of the...</td>\n",
       "      <td>The Great Pyramid of Giza</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The response is fully accurate, complete, and ...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The context is highly relevant and surfaces th...</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The response fully answers the question, provi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       outputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                    outputs.response  \\\n",
       "0  The event that started on **July 28, 1914** wa...   \n",
       "1  The first person to walk on the moon was **Nei...   \n",
       "2  The year **1776** is highly significant in Ame...   \n",
       "3  The **Berlin Wall** fell in 1989, symbolizing ...   \n",
       "4  The ancient city buried by the eruption of Mou...   \n",
       "5  The British Prime Minister during most of Worl...   \n",
       "6  The name of the ship that sank on its maiden v...   \n",
       "7          Genghis Khan ruled the **Mongol Empire**.   \n",
       "8  The primary cause of the American Civil War wa...   \n",
       "9  The **Great Pyramid of Giza** was the ancient ...   \n",
       "\n",
       "                                        inputs.query  \\\n",
       "0               What event started on July 28, 1914?   \n",
       "1      Who was the first person to walk on the moon?   \n",
       "2  What was the significance of the year 1776 in ...   \n",
       "3  Which wall fell in 1989, symbolizing the end o...   \n",
       "4  What ancient city was buried by the eruption o...   \n",
       "5  Who was the British Prime Minister during Worl...   \n",
       "6  What was the name of the ship that sank on its...   \n",
       "7            Which empire was ruled by Genghis Khan?   \n",
       "8  What was the primary cause of the American Civ...   \n",
       "9  Which ancient wonder was located in Egypt and ...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  It involved multiple countries and lasted unti...   \n",
       "1  The event occurred during the Apollo 11 missio...   \n",
       "2  A key document was signed declaring independen...   \n",
       "3       It divided a German city into East and West.   \n",
       "4  The city's ruins were rediscovered in the 18th...   \n",
       "5  He is famous for his leadership and speeches, ...   \n",
       "6  It was deemed 'unsinkable' before it hit an ic...   \n",
       "7  This empire became the largest contiguous land...   \n",
       "8  The conflict between the Northern and Southern...   \n",
       "9  It is the only one of the Seven Wonders of the...   \n",
       "\n",
       "               inputs.ground_truth  outputs.relevance.relevance  \\\n",
       "0                      World War I                            5   \n",
       "1                   Neil Armstrong                            5   \n",
       "2  The Declaration of Independence                            5   \n",
       "3                  The Berlin Wall                            4   \n",
       "4                          Pompeii                            4   \n",
       "5                Winston Churchill                            5   \n",
       "6                      RMS Titanic                            4   \n",
       "7                The Mongol Empire                            4   \n",
       "8                          Slavery                            5   \n",
       "9        The Great Pyramid of Giza                            5   \n",
       "\n",
       "   outputs.relevance.gpt_relevance  \\\n",
       "0                                5   \n",
       "1                                5   \n",
       "2                                5   \n",
       "3                                4   \n",
       "4                                4   \n",
       "5                                5   \n",
       "6                                4   \n",
       "7                                4   \n",
       "8                                5   \n",
       "9                                5   \n",
       "\n",
       "                  outputs.relevance.relevance_reason  \\\n",
       "0  The response is fully accurate, complete, and ...   \n",
       "1  The response is accurate, complete, and includ...   \n",
       "2  The response is not only complete and accurate...   \n",
       "3  The response fully and accurately answers the ...   \n",
       "4  The response is accurate and fully answers the...   \n",
       "5  The response is accurate, complete, and includ...   \n",
       "6  The response fully and accurately answers the ...   \n",
       "7  The response fully and accurately answers the ...   \n",
       "8  The response fully answers the question and pr...   \n",
       "9  The response is fully accurate, complete, and ...   \n",
       "\n",
       "  outputs.relevance.relevance_result  outputs.relevance.relevance_threshold  \\\n",
       "0                               pass                                      3   \n",
       "1                               pass                                      3   \n",
       "2                               pass                                      3   \n",
       "3                               pass                                      3   \n",
       "4                               pass                                      3   \n",
       "5                               pass                                      3   \n",
       "6                               pass                                      3   \n",
       "7                               pass                                      3   \n",
       "8                               pass                                      3   \n",
       "9                               pass                                      3   \n",
       "\n",
       "   ...  outputs.groundedness.groundedness_result  \\\n",
       "0  ...                                      pass   \n",
       "1  ...                                      pass   \n",
       "2  ...                                      pass   \n",
       "3  ...                                      pass   \n",
       "4  ...                                      pass   \n",
       "5  ...                                      pass   \n",
       "6  ...                                      pass   \n",
       "7  ...                                      pass   \n",
       "8  ...                                      pass   \n",
       "9  ...                                      pass   \n",
       "\n",
       "   outputs.groundedness.groundedness_threshold outputs.retrieval.retrieval  \\\n",
       "0                                            3                           2   \n",
       "1                                            3                           2   \n",
       "2                                            3                           5   \n",
       "3                                            3                           2   \n",
       "4                                            3                           1   \n",
       "5                                            3                           1   \n",
       "6                                            3                           2   \n",
       "7                                            3                           5   \n",
       "8                                            3                           5   \n",
       "9                                            3                           5   \n",
       "\n",
       "  outputs.retrieval.gpt_retrieval  \\\n",
       "0                               2   \n",
       "1                               2   \n",
       "2                               5   \n",
       "3                               2   \n",
       "4                               1   \n",
       "5                               1   \n",
       "6                               2   \n",
       "7                               5   \n",
       "8                               5   \n",
       "9                               5   \n",
       "\n",
       "                  outputs.retrieval.retrieval_reason  \\\n",
       "0  The context is partially relevant because it g...   \n",
       "1  The context is partially relevant because it r...   \n",
       "2  The context is highly relevant, directly answe...   \n",
       "3  The context is partially relevant as it hints ...   \n",
       "4  The context does not provide relevant informat...   \n",
       "5  The context does not provide the name of the B...   \n",
       "6  The context is somewhat relevant but does not ...   \n",
       "7  The context is highly relevant to the query, d...   \n",
       "8  The context is highly relevant, directly addre...   \n",
       "9  The context is highly relevant and surfaces th...   \n",
       "\n",
       "   outputs.retrieval.retrieval_result  outputs.retrieval.retrieval_threshold  \\\n",
       "0                                fail                                      3   \n",
       "1                                fail                                      3   \n",
       "2                                pass                                      3   \n",
       "3                                fail                                      3   \n",
       "4                                fail                                      3   \n",
       "5                                fail                                      3   \n",
       "6                                fail                                      3   \n",
       "7                                pass                                      3   \n",
       "8                                pass                                      3   \n",
       "9                                pass                                      3   \n",
       "\n",
       "  outputs.helpfulness.helpfulness  \\\n",
       "0                               5   \n",
       "1                               5   \n",
       "2                               5   \n",
       "3                               5   \n",
       "4                               5   \n",
       "5                               5   \n",
       "6                               5   \n",
       "7                               5   \n",
       "8                               5   \n",
       "9                               5   \n",
       "\n",
       "              outputs.helpfulness.helpfulness_reason  line_number  \n",
       "0  The response fully answers the question, accur...            0  \n",
       "1  The response is fully accurate, complete, and ...            1  \n",
       "2  The response is fully helpful, providing a com...            2  \n",
       "3  The response is entirely helpful, directly ans...            3  \n",
       "4  The response fully and accurately answers the ...            4  \n",
       "5  The response is entirely helpful, accurately n...            5  \n",
       "6  The response is entirely helpful, directly ans...            6  \n",
       "7  The response fully and accurately answers the ...            7  \n",
       "8  The response fully answers the question, accur...            8  \n",
       "9  The response fully answers the question, provi...            9  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result[\"rows\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-evaluation in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: promptflow-devkit>=1.17.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: promptflow-core>=1.17.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (2.9.0)\n",
      "Requirement already satisfied: azure-identity>=1.16.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.21.0)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.32.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (12.24.0)\n",
      "Requirement already satisfied: httpx>=0.25.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (2.2.3)\n",
      "Requirement already satisfied: openai>=1.78.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (1.79.0)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (0.18.10)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (0.7.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-ai-evaluation) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (6.0.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.18.3)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.12.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (44.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-storage-blob>=12.10.0->azure-ai-evaluation) (0.6.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.1->azure-ai-evaluation) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2>=3.1.6->azure-ai-evaluation) (2.1.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (4.67.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (2.10.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2024.1)\n",
      "Requirement already satisfied: docstring_parser in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.16)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.115.6)\n",
      "Requirement already satisfied: filetype>=1.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (3.0.3)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (4.23.0)\n",
      "Requirement already satisfied: promptflow-tracing==1.17.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (5.9.8)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.8.0)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.5.1)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.0b32)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.16.1)\n",
      "Requirement already satisfied: flask-cors<6.0.0,>=5.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.0)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.43)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (24.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.21.3)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: pillow<11.1.0,>=10.1.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.3.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.0.7)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.1)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\alevret\\appdata\\roaming\\python\\python312\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (306)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (2.0.31)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.7.3)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.8)\n",
      "Requirement already satisfied: fixedint==0.1.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-api~=1.26 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.41.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.0.6)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: aniso8601>=0.82 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (9.0.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (6.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (4.0.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.18.1)\n",
      "Requirement already satisfied: jaraco.classes in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.4.0)\n",
      "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.2.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (23.2)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity>=1.16.0->azure-ai-evaluation) (2.10.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.2.15)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.28.2)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-proto==1.28.2->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.28.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.22)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.1)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api~=1.26->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.2.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.49b2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alevret\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.26->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.21.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\alevret\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\alevret\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\alevret\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg@3': 0.31075932533963707,\n",
       " 'xdcg@3': 39.285714285714285,\n",
       " 'fidelity': 0.39285714285714285,\n",
       " 'top1_relevance': 2,\n",
       " 'top3_max_relevance': 3,\n",
       " 'holes': 2,\n",
       " 'holes_ratio': 0.4,\n",
       " 'total_retrieved_documents': 5,\n",
       " 'total_ground_truth_documents': 5,\n",
       " 'ndcg@3_result': 'fail',\n",
       " 'ndcg@3_threshold': 0.5,\n",
       " 'ndcg@3_higher_is_better': True,\n",
       " 'xdcg@3_result': 'fail',\n",
       " 'xdcg@3_threshold': 50.0,\n",
       " 'xdcg@3_higher_is_better': True,\n",
       " 'fidelity_result': 'fail',\n",
       " 'fidelity_threshold': 0.5,\n",
       " 'fidelity_higher_is_better': True,\n",
       " 'top1_relevance_result': 'fail',\n",
       " 'top1_relevance_threshold': 50.0,\n",
       " 'top1_relevance_higher_is_better': True,\n",
       " 'top3_max_relevance_result': 'fail',\n",
       " 'top3_max_relevance_threshold': 50.0,\n",
       " 'top3_max_relevance_higher_is_better': True,\n",
       " 'holes_result': 'fail',\n",
       " 'holes_threshold': 0,\n",
       " 'holes_higher_is_better': False,\n",
       " 'holes_ratio_result': 'fail',\n",
       " 'holes_ratio_threshold': 0,\n",
       " 'holes_ratio_higher_is_better': False,\n",
       " 'total_retrieved_documents_result': 'fail',\n",
       " 'total_retrieved_documents_threshold': 50,\n",
       " 'total_retrieved_documents_higher_is_better': True,\n",
       " 'total_ground_truth_documents_result': 'fail',\n",
       " 'total_ground_truth_documents_threshold': 50,\n",
       " 'total_ground_truth_documents_higher_is_better': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.evaluation import DocumentRetrievalEvaluator\n",
    "\n",
    "# these query_relevance_label are given by your human- or LLM-judges.\n",
    "retrieval_ground_truth = [\n",
    "    {\n",
    "        \"document_id\": \"1\",\n",
    "        \"query_relevance_label\": 4\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"2\",\n",
    "        \"query_relevance_label\": 2\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"3\",\n",
    "        \"query_relevance_label\": 3\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"4\",\n",
    "        \"query_relevance_label\": 1\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"5\",\n",
    "        \"query_relevance_label\": 0\n",
    "    },\n",
    "]\n",
    "# the min and max of the label scores are inputs to document retrieval evaluator\n",
    "ground_truth_label_min = 0\n",
    "ground_truth_label_max = 4\n",
    "\n",
    "# these relevance scores come from your search retrieval system\n",
    "retrieved_documents = [\n",
    "    {\n",
    "        \"document_id\": \"2\",\n",
    "        \"relevance_score\": 45.1\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"6\",\n",
    "        \"relevance_score\": 35.8\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"3\",\n",
    "        \"relevance_score\": 29.2\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"5\",\n",
    "        \"relevance_score\": 25.4\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"7\",\n",
    "        \"relevance_score\": 18.8\n",
    "    },\n",
    "]\n",
    "\n",
    "document_retrieval_evaluator = DocumentRetrievalEvaluator(\n",
    "    ground_truth_label_min=ground_truth_label_min, \n",
    "    ground_truth_label_max=ground_truth_label_max,\n",
    "    ndcg_threshold = 0.5,\n",
    "    xdcg_threshold = 50.0,\n",
    "    fidelity_threshold = 0.5,\n",
    "    top1_relevance_threshold = 50.0,\n",
    "    top3_max_relevance_threshold = 50.0,\n",
    "    total_retrieved_documents_threshold = 50,\n",
    "    total_ground_truth_documents_threshold = 50\n",
    ")\n",
    "document_retrieval_evaluator(retrieval_ground_truth=retrieval_ground_truth, retrieved_documents=retrieved_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
