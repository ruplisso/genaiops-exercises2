{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95b03d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb15c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_QNxGQefOZrxb8xknXjGGPcer\n",
      "Created thread, ID: thread_WZ1lL3DLldHTDLqTX7Q21hUP\n",
      "Created message, ID: msg_WvDdkXeip6CN6qKxBqDrTKmN\n",
      "Created run, ID: run_vAhKjAJ75l5ev9loCKcTi50O\n",
      "Run completed with status: RunStatus.COMPLETED\n",
      "Role: user\n",
      "Content: [{'type': 'text', 'text': {'value': 'Hello, what about the weather in New York?', 'annotations': []}}]\n",
      "----------------------------------------\n",
      "Role: assistant\n",
      "Content: [{'type': 'text', 'text': {'value': 'The weather in New York is currently sunny with a temperature of 25°C.', 'annotations': []}}]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AIAgentConverter: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class FDPAgentDataRetriever: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AIAgentDataRetriever: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data saved to c:\\Users\\ruplisso\\Documents\\GitHub\\genaiops-exercises2\\solutions\\06_Agents_Evaluator\\evaluation_input_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.agents.models import FunctionTool\n",
    "from azure.ai.evaluation import AIAgentConverter, IntentResolutionEvaluator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "# Initialize the AI Project Endpoint from environment variables\n",
    "ai_project_endpoint=os.environ[\"AI_PROJECT_ENDPOINT\"]\n",
    "\n",
    "# Create a fake fetch_weather function\n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather information for the specified location.\n",
    "\n",
    "    :param location: The location to fetch weather for.\n",
    "    :return: Weather information as a JSON string.\n",
    "    \"\"\"\n",
    "    # Mock weather data for demonstration purposes\n",
    "    mock_weather_data = {\"New York\": \"Sunny, 25°C\", \"London\": \"Cloudy, 18°C\", \"Tokyo\": \"Rainy, 22°C\"}\n",
    "    weather = mock_weather_data.get(location, \"Weather data not available for this location.\")\n",
    "    return json.dumps({\"weather\": weather})\n",
    "\n",
    "# Define user functions\n",
    "user_functions = {fetch_weather}\n",
    "\n",
    "# Initialize the AIProjectClient\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=ai_project_endpoint,\n",
    "    credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "# Initialize the FunctionTool with user-defined functions\n",
    "functions = FunctionTool(functions=user_functions)\n",
    "\n",
    "with project_client:\n",
    "    \n",
    "    # Create an agent with custom functions\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        name=\"my-agent-to-be-evaluated\",\n",
    "        instructions=\"You are a helpful agent\",\n",
    "        tools=functions.definitions,\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "    # Create a thread for communication\n",
    "    thread = project_client.agents.threads.create()\n",
    "    print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "    # Send a message to the thread\n",
    "    message = project_client.agents.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Hello, what about the weather in New York?\",\n",
    "    )\n",
    "    print(f\"Created message, ID: {message['id']}\")\n",
    "\n",
    "    run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "    print(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "    # Poll the run status until it is completed or requires action\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        time.sleep(1)\n",
    "        run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "        if run.status == \"requires_action\":\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "            for tool_call in tool_calls:\n",
    "                if tool_call.function.name == \"fetch_weather\":\n",
    "                    output = fetch_weather(\"New York\")\n",
    "                    tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": output})\n",
    "            project_client.agents.runs.submit_tool_outputs(thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs)\n",
    "\n",
    "    print(f\"Run completed with status: {run.status}\")\n",
    "\n",
    "    # Fetch and log all messages from the thread\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id,order=\"asc\")\n",
    "    for message in messages:\n",
    "        print(f\"Role: {message['role']}\")\n",
    "        print(f\"Content: {message['content']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # Initialize the converter for Azure AI agents.\n",
    "    converter = AIAgentConverter(project_client)\n",
    "\n",
    "    # Specify the thread and run ID.\n",
    "    thread_id = thread.id\n",
    "    run_id = run.id\n",
    "    converted_data = converter.convert(thread_id, run_id)\n",
    "\n",
    "    # Specify a file path to save the agent output (evaluation input data) to.\n",
    "    filename = os.path.join(os.getcwd(), \"evaluation_input_data.jsonl\")\n",
    "    evaluation_data = converter.prepare_evaluation_data(thread_ids=thread_id, filename=filename) \n",
    "    print(f\"Evaluation data saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecc59b",
   "metadata": {},
   "source": [
    "Display Converted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e41da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': [{'role': 'system', 'content': 'You are a helpful agent'},\n",
       "  {'createdAt': '2025-08-04T14:28:33Z',\n",
       "   'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Hello, what about the weather in New York?'}]}],\n",
       " 'response': [{'createdAt': '2025-08-04T14:28:36Z',\n",
       "   'run_id': 'run_vAhKjAJ75l5ev9loCKcTi50O',\n",
       "   'role': 'assistant',\n",
       "   'content': [{'type': 'tool_call',\n",
       "     'tool_call_id': 'call_t1BOebQ12iMQ7Jd3TqqmZE91',\n",
       "     'name': 'fetch_weather',\n",
       "     'arguments': {'location': 'New York'}}]},\n",
       "  {'createdAt': '2025-08-04T14:28:39Z',\n",
       "   'run_id': 'run_vAhKjAJ75l5ev9loCKcTi50O',\n",
       "   'tool_call_id': 'call_t1BOebQ12iMQ7Jd3TqqmZE91',\n",
       "   'role': 'tool',\n",
       "   'content': [{'type': 'tool_result',\n",
       "     'tool_result': {'weather': 'Sunny, 25°C'}}]},\n",
       "  {'createdAt': '2025-08-04T14:28:40Z',\n",
       "   'run_id': 'run_vAhKjAJ75l5ev9loCKcTi50O',\n",
       "   'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'The weather in New York is currently sunny with a temperature of 25°C.'}]}],\n",
       " 'tool_definitions': [{'name': 'fetch_weather',\n",
       "   'type': 'function',\n",
       "   'description': 'Fetches the weather information for the specified location.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'location': {'type': 'string',\n",
       "      'description': 'The location to fetch weather for.'}}}}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa1ec76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class TaskAdherenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ToolCallAccuracyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntentResolutionEvaluator\n",
      "{\n",
      "    \"intent_resolution\": 5.0,\n",
      "    \"intent_resolution_result\": \"pass\",\n",
      "    \"intent_resolution_threshold\": 3,\n",
      "    \"intent_resolution_reason\": \"User wanted the current weather in New York. Agent provided accurate and relevant information, including conditions and temperature, fully resolving the intent with clarity and precision.\"\n",
      "}\n",
      "TaskAdherenceEvaluator\n",
      "{\n",
      "    \"task_adherence\": 5.0,\n",
      "    \"task_adherence_result\": \"pass\",\n",
      "    \"task_adherence_threshold\": 3,\n",
      "    \"task_adherence_reason\": \"The assistant correctly identified the task, used the appropriate tool, and provided a clear and accurate weather update for New York.\"\n",
      "}\n",
      "ToolCallAccuracyEvaluator\n",
      "{\n",
      "    \"tool_call_accuracy\": 5.0,\n",
      "    \"tool_call_accuracy_result\": \"pass\",\n",
      "    \"tool_call_accuracy_threshold\": 3,\n",
      "    \"tool_call_accuracy_reason\": \"Let's think step by step: The user asked about the weather in New York. The agent correctly called the 'fetch_weather' tool with the parameter 'location' set to 'New York', which is grounded in the user's query. The tool returned the weather information successfully without any errors. There were no excessive or unnecessary tool calls made, and no tool calls were missing. The tool call was efficient and fully addressed the user's query. Based on the definitions, this is a Level 5 'pass'.\",\n",
      "    \"details\": {\n",
      "        \"tool_calls_made_by_agent\": 1,\n",
      "        \"correct_tool_calls_made_by_agent\": 1,\n",
      "        \"per_tool_call_details\": [\n",
      "            {\n",
      "                \"tool_name\": \"fetch_weather\",\n",
      "                \"total_calls_required\": 1,\n",
      "                \"correct_calls_made_by_agent\": 1,\n",
      "                \"correct_tool_percentage\": 1.0,\n",
      "                \"tool_call_errors\": 0,\n",
      "                \"tool_success_result\": \"pass\"\n",
      "            }\n",
      "        ],\n",
      "        \"excess_tool_calls\": {\n",
      "            \"total\": 0,\n",
      "            \"details\": []\n",
      "        },\n",
      "        \"missing_tool_calls\": {\n",
      "            \"total\": 0,\n",
      "            \"details\": []\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This is specific to agentic workflows.\n",
    "from azure.ai.evaluation import IntentResolutionEvaluator, TaskAdherenceEvaluator, ToolCallAccuracyEvaluator\n",
    "\n",
    "# Other quality, risk, and safety metrics:\n",
    "from azure.ai.evaluation import RelevanceEvaluator, CoherenceEvaluator, CodeVulnerabilityEvaluator, ContentSafetyEvaluator, IndirectAttackEvaluator, FluencyEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model_config = {\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}\n",
    "\n",
    "reasoning_model_config = {\n",
    "    \"azure_deployment\": \"o4-mini\",\n",
    "    \"api_key\": os.getenv(\"AZURE_API_KEY\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_ENDPOINT\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_API_VERSION\"),\n",
    "}\n",
    "\n",
    "# Evaluators with reasoning model support\n",
    "quality_evaluators = {evaluator.__name__: evaluator(model_config=model_config) for evaluator in [IntentResolutionEvaluator, TaskAdherenceEvaluator, ToolCallAccuracyEvaluator]}\n",
    "\n",
    "## Using Azure AI Foundry (non-Hub) project endpoint, example: AZURE_AI_PROJECT=https://your-account.services.ai.azure.com/api/projects/your-project\n",
    "\n",
    "# azure_ai_project = \"https://projetagent-resource.services.ai.azure.com/api/projects/projetagent\"\n",
    "\n",
    "# Reference the quality and safety evaluator list above.\n",
    "quality_and_safety_evaluators = {**quality_evaluators}\n",
    "\n",
    "for name, evaluator in quality_and_safety_evaluators.items():\n",
    "    result = evaluator(**converted_data)\n",
    "    print(name)\n",
    "    print(json.dumps(result, indent=4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3188eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-04 16:33:15 +0200   15556 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-08-04 16:33:15 +0200   15556 execution.bulk     INFO     Average execution time for completed lines: 3.89 seconds. Estimated time for incomplete lines: 7.78 seconds.\n",
      "2025-08-04 16:33:15 +0200   15556 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2025-08-04 16:33:15 +0200   15556 execution.bulk     INFO     Average execution time for completed lines: 1.96 seconds. Estimated time for incomplete lines: 1.96 seconds.\n",
      "2025-08-04 16:33:15 +0200   15556 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-08-04 16:33:15 +0200   15556 execution.bulk     INFO     Average execution time for completed lines: 1.36 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-08-04 16:33:16 +0200   11444 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-08-04 16:33:16 +0200   11444 execution.bulk     INFO     Average execution time for completed lines: 4.31 seconds. Estimated time for incomplete lines: 8.62 seconds.\n",
      "2025-08-04 16:33:16 +0200   11444 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2025-08-04 16:33:16 +0200   11444 execution.bulk     INFO     Average execution time for completed lines: 2.16 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-08-04 16:33:16 +0200   11444 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-08-04 16:33:16 +0200   11444 execution.bulk     INFO     Average execution time for completed lines: 1.45 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"task_adherence_20250804_143311_831133\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-04 14:33:11.831133+00:00\"\n",
      "Duration: \"0:00:04.540960\"\n",
      "\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"intent_resolution_20250804_143311_816047\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-04 14:33:11.816047+00:00\"\n",
      "Duration: \"0:00:04.582877\"\n",
      "\n",
      "2025-08-04 16:33:17 +0200   42560 execution.bulk     INFO     Finished 1 / 3 lines.\n",
      "2025-08-04 16:33:17 +0200   42560 execution.bulk     INFO     Average execution time for completed lines: 6.13 seconds. Estimated time for incomplete lines: 12.26 seconds.\n",
      "2025-08-04 16:33:17 +0200   42560 execution.bulk     INFO     Finished 2 / 3 lines.\n",
      "2025-08-04 16:33:17 +0200   42560 execution.bulk     INFO     Average execution time for completed lines: 3.08 seconds. Estimated time for incomplete lines: 3.08 seconds.\n",
      "2025-08-04 16:33:19 +0200   42560 execution.bulk     INFO     Finished 3 / 3 lines.\n",
      "2025-08-04 16:33:19 +0200   42560 execution.bulk     INFO     Average execution time for completed lines: 2.39 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"tool_call_accuracy_20250804_143311_826648\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-04 14:33:11.826648+00:00\"\n",
      "Duration: \"0:00:07.524565\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"tool_call_accuracy\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:07.524565\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"intent_resolution\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:04.582877\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"task_adherence\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:04.540960\",\n",
      "        \"completed_lines\": 3,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "{'tool_call_accuracy.tool_call_accuracy': 5.0, 'tool_call_accuracy.tool_call_accuracy_threshold': 3.0, 'intent_resolution.intent_resolution': 5.0, 'intent_resolution.intent_resolution_threshold': 3.0, 'task_adherence.task_adherence': 5.0, 'task_adherence.task_adherence_threshold': 3.0, 'tool_call_accuracy.binary_aggregate': 1.0, 'intent_resolution.binary_aggregate': 1.0, 'task_adherence.binary_aggregate': 1.0}\n",
      "AI Foundry URL: https://ai.azure.com/resource/build/evaluation/a5ab14f0-4dfc-4094-b743-9fbd5d00ac21?wsid=/subscriptions/8babb7f9-50f7-498f-9e0a-8bef4389331d/resourceGroups/rg-ruplisso-3364/providers/Microsoft.CognitiveServices/accounts/projetagent-resource/projects/projetagent&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    ToolCallAccuracyEvaluator,\n",
    "    IntentResolutionEvaluator,\n",
    "    TaskAdherenceEvaluator,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ai_project_endpoint=os.environ[\"AI_PROJECT_ENDPOINT\"]\n",
    "\n",
    "intent_resolution = IntentResolutionEvaluator(model_config=model_config)\n",
    "tool_call_accuracy = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "task_adherence = TaskAdherenceEvaluator(model_config=model_config)\n",
    "\n",
    "response = evaluate(\n",
    "    data=filename,\n",
    "    evaluation_name=\"agent demo - batch run\",\n",
    "    evaluators={\n",
    "        \"tool_call_accuracy\": tool_call_accuracy,\n",
    "        \"intent_resolution\": intent_resolution,\n",
    "        \"task_adherence\": task_adherence,\n",
    "    },\n",
    "    # optionally, log your results to your Azure AI Foundry project for rich visualization \n",
    "    azure_ai_project = ai_project_endpoint\n",
    "    #\"https://projetagent-resource.services.ai.azure.com/api/projects/projetagent\", # example: https://your-account.services.ai.azure.com/api/projects/your-project\n",
    ")\n",
    "# Inspect the average scores at a high level.\n",
    "print(response[\"metrics\"])\n",
    "\n",
    "# Use the URL to inspect the results on the UI.\n",
    "print(f'AI Foundry URL: {response.get(\"studio_url\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiops2envagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
