{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6ab610",
   "metadata": {},
   "source": [
    "https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33a09b",
   "metadata": {},
   "source": [
    "### Create a custom Python function and register it in the Toolset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e82de94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from azure.ai.agents.models import FunctionTool, ToolSet\n",
    "from typing import Set, Callable, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "weather_api_key = os.environ.get(\"WEATHER_API_KEY\")\n",
    "\n",
    "# Define a custom Python function.\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the weather information for the specified location.\n",
    "\n",
    "    :param location (str): The location to fetch weather for.\n",
    "    :return: Weather information as a JSON string.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    url = f\"http://api.weatherapi.com/v1/current.json?key={weather_api_key}&q={city}&aqi=no\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        condition = data[\"current\"][\"condition\"][\"text\"]\n",
    "        temp_c = data[\"current\"][\"temp_c\"]\n",
    "        return {\"condition\": condition,\"temperature\": temp_c}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "    \n",
    "user_functions: Set[Callable[..., Any]] = {\n",
    "    get_weather,\n",
    "}\n",
    "\n",
    "# Add tools that the agent will use. \n",
    "functions = FunctionTool(user_functions)\n",
    "\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a087b31",
   "metadata": {},
   "source": [
    "### Create the agent, iniate the thread, add message and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0387b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_TtvNELRym7RMUPleSEzpx2Bp\n",
      "Created thread, ID: thread_rF0qsrrBRbu4qefZtzqOzUAh\n",
      "Created message, ID: msg_KEFGY3ka6vcvE3qIzUb9XMFX\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "Role: user\n",
      "Content: [{'type': 'text', 'text': {'value': 'What is the weather in Tokyo today?', 'annotations': []}}]\n",
      "----------------------------------------\n",
      "Role: assistant\n",
      "Content: [{'type': 'text', 'text': {'value': 'The weather in Tokyo today is partly cloudy with a temperature of 33.3Â°C.', 'annotations': []}}]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.ai.agents \n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "# Create an Azure AI Client from an endpoint, copied from your Azure AI Foundry project.\n",
    "project_endpoint = os.environ[\"AI_PROJECT_ENDPOINT\"]  # Ensure the PROJECT_ENDPOINT environment variable is set\n",
    "\n",
    "# Create an AIProjectClient instance\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=project_endpoint,\n",
    "    credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    ")\n",
    "\n",
    "# Create an agent with the toolset \n",
    "agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o\",  # Model deployment name\n",
    "    name=\"my-agent-to-be-evaluated\",  # Name of the agent\n",
    "    instructions=\"You are a helpful agent\",  # Instructions for the agent\n",
    "    toolset=toolset\n",
    ")\n",
    "print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "# Enable auto function calls for the agent\n",
    "project_client.agents.enable_auto_function_calls(toolset)\n",
    "\n",
    "# Create a thread for communication\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Add a message to the thread\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",  # Role of the message sender\n",
    "    content=\"What is the weather in Tokyo today?\",  # Message content\n",
    ")\n",
    "print(f\"Created message, ID: {message['id']}\")\n",
    "\n",
    "# Create and process an agent run\n",
    "run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "# Check if the run failed\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Fetch and log all messages\n",
    "messages = project_client.agents.messages.list(thread_id=thread.id,order=\"asc\")\n",
    "for message in messages:\n",
    "    print(f\"Role: {message['role']}\")\n",
    "    print(f\"Content: {message['content']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0300f3",
   "metadata": {},
   "source": [
    "### Get the converted data from the run/thread id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65d73c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import AIAgentConverter\n",
    "\n",
    "# Initialize the converter for Azure AI agents.\n",
    "converter = AIAgentConverter(project_client)\n",
    "\n",
    "# Specify the thread and run ID.\n",
    "thread_id = thread.id\n",
    "run_id = run.id\n",
    "\n",
    "converted_data = converter.convert(thread_id, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442daafb",
   "metadata": {},
   "source": [
    "### Evaluate a single agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de7fa05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntentResolutionEvaluator\n",
      "{\n",
      "    \"intent_resolution\": 5.0,\n",
      "    \"intent_resolution_result\": \"pass\",\n",
      "    \"intent_resolution_threshold\": 3,\n",
      "    \"intent_resolution_reason\": \"User wanted the current weather in Tokyo. Agent provided an accurate and complete response, including conditions and temperature, fully resolving the intent with clarity and precision.\"\n",
      "}\n",
      "TaskAdherenceEvaluator\n",
      "{\n",
      "    \"task_adherence\": 5.0,\n",
      "    \"task_adherence_result\": \"pass\",\n",
      "    \"task_adherence_threshold\": 3,\n",
      "    \"task_adherence_reason\": \"The assistant correctly identified the task, used the appropriate tool, and provided a clear and accurate weather update for Tokyo, fully satisfying the user's request.\"\n",
      "}\n",
      "ToolCallAccuracyEvaluator\n",
      "{\n",
      "    \"tool_call_accuracy\": 5.0,\n",
      "    \"tool_call_accuracy_result\": \"pass\",\n",
      "    \"tool_call_accuracy_threshold\": 3,\n",
      "    \"tool_call_accuracy_reason\": \"Let's think step by step: The user asked for the weather in Tokyo today. The agent correctly called the 'get_weather' tool with the parameter 'city' set to 'Tokyo', which is grounded in the user's query. The tool returned the weather information without any errors, and the agent did not make any unnecessary or excessive tool calls. No missing tool calls were identified, and the tool call was efficient and relevant to the user's query. Based on the definitions, this is an optimal solution.\",\n",
      "    \"details\": {\n",
      "        \"tool_calls_made_by_agent\": 1,\n",
      "        \"correct_tool_calls_made_by_agent\": 1,\n",
      "        \"per_tool_call_details\": [\n",
      "            {\n",
      "                \"tool_name\": \"get_weather\",\n",
      "                \"total_calls_required\": 1,\n",
      "                \"correct_calls_made_by_agent\": 1,\n",
      "                \"correct_tool_percentage\": 1.0,\n",
      "                \"tool_call_errors\": 0,\n",
      "                \"tool_success_result\": \"pass\"\n",
      "            }\n",
      "        ],\n",
      "        \"excess_tool_calls\": {\n",
      "            \"total\": 0,\n",
      "            \"details\": []\n",
      "        },\n",
      "        \"missing_tool_calls\": {\n",
      "            \"total\": 0,\n",
      "            \"details\": []\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# This is specific to agentic workflows.\n",
    "from azure.ai.evaluation import IntentResolutionEvaluator, TaskAdherenceEvaluator, ToolCallAccuracyEvaluator\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model_config = {\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}\n",
    "\n",
    "# Evaluators with standard model support\n",
    "quality_evaluators = {evaluator.__name__: evaluator(model_config=model_config) for evaluator in [IntentResolutionEvaluator, TaskAdherenceEvaluator, ToolCallAccuracyEvaluator]}\n",
    "\n",
    "# Reference the quality and safety evaluator list above.\n",
    "quality_and_safety_evaluators = {**quality_evaluators}\n",
    "\n",
    "for name, evaluator in quality_and_safety_evaluators.items():\n",
    "    result = evaluator(**converted_data)\n",
    "    print(name)\n",
    "    print(json.dumps(result, indent=4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9dde0d",
   "metadata": {},
   "source": [
    "### Evaluate multiple agent runs or threads\n",
    "\n",
    "First, convert your agent thread data into a file via our converter support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8959b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data saved to c:\\Users\\ruplisso\\Documents\\GitHub\\genaiops-exercises2\\solutions\\06_Agents_Evaluator\\evaluation_input_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Specify a file path to save the agent output (evaluation input data) to.\n",
    "filename = os.path.join(os.getcwd(), \"evaluation_input_data.jsonl\")\n",
    "\n",
    "evaluation_data = converter.prepare_evaluation_data(thread_ids=thread_id, filename=filename) \n",
    "\n",
    "print(f\"Evaluation data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad761c9",
   "metadata": {},
   "source": [
    "Leverage the Batch evaluate API for asynchronous evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e02041e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-07 10:36:21 +0200   24000 execution.bulk     INFO     Finished 1 / 12 lines.\n",
      "2025-08-07 10:36:21 +0200   24000 execution.bulk     INFO     Average execution time for completed lines: 11.52 seconds. Estimated time for incomplete lines: 126.72 seconds.\n",
      "2025-08-07 10:36:21 +0200   24000 execution.bulk     INFO     Finished 7 / 12 lines.\n",
      "2025-08-07 10:36:21 +0200   24000 execution.bulk     INFO     Average execution time for completed lines: 1.7 seconds. Estimated time for incomplete lines: 8.5 seconds.\n",
      "2025-08-07 10:36:22 +0200   31044 execution.bulk     INFO     Finished 1 / 12 lines.\n",
      "2025-08-07 10:36:22 +0200   31044 execution.bulk     INFO     Average execution time for completed lines: 12.39 seconds. Estimated time for incomplete lines: 136.29 seconds.\n",
      "2025-08-07 10:36:22 +0200   24000 execution.bulk     INFO     Finished 8 / 12 lines.\n",
      "2025-08-07 10:36:22 +0200   24000 execution.bulk     INFO     Average execution time for completed lines: 1.56 seconds. Estimated time for incomplete lines: 6.24 seconds.\n",
      "2025-08-07 10:36:22 +0200   31044 execution.bulk     INFO     Finished 5 / 12 lines.\n",
      "2025-08-07 10:36:22 +0200   31044 execution.bulk     INFO     Average execution time for completed lines: 2.55 seconds. Estimated time for incomplete lines: 17.85 seconds.\n",
      "2025-08-07 10:36:22 +0200   31044 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-08-07 10:36:22 +0200   31044 execution.bulk     INFO     Average execution time for completed lines: 1.42 seconds. Estimated time for incomplete lines: 4.26 seconds.\n",
      "2025-08-07 10:36:22 +0200   24000 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-08-07 10:36:22 +0200   24000 execution.bulk     INFO     Average execution time for completed lines: 1.43 seconds. Estimated time for incomplete lines: 4.29 seconds.\n",
      "2025-08-07 10:36:22 +0200   24000 execution.bulk     INFO     Finished 10 / 12 lines.\n",
      "2025-08-07 10:36:22 +0200   24000 execution.bulk     INFO     Average execution time for completed lines: 1.29 seconds. Estimated time for incomplete lines: 2.58 seconds.\n",
      "2025-08-07 10:36:23 +0200   31044 execution.bulk     INFO     Finished 10 / 12 lines.\n",
      "2025-08-07 10:36:23 +0200   31044 execution.bulk     INFO     Average execution time for completed lines: 1.3 seconds. Estimated time for incomplete lines: 2.6 seconds.\n",
      "2025-08-07 10:36:23 +0200   24000 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-08-07 10:36:23 +0200   24000 execution.bulk     INFO     Average execution time for completed lines: 1.22 seconds. Estimated time for incomplete lines: 1.22 seconds.\n",
      "2025-08-07 10:36:23 +0200   24000 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-08-07 10:36:23 +0200   24000 execution.bulk     INFO     Average execution time for completed lines: 1.14 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-08-07 10:36:23 +0200   45032 execution.bulk     INFO     Finished 1 / 12 lines.\n",
      "2025-08-07 10:36:23 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 13.7 seconds. Estimated time for incomplete lines: 150.7 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"intent_resolution_20250807_083609_997816\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-07 08:36:09.997816+00:00\"\n",
      "Duration: \"0:00:13.917811\"\n",
      "\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Finished 2 / 12 lines.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 7.07 seconds. Estimated time for incomplete lines: 70.7 seconds.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Finished 3 / 12 lines.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 4.71 seconds. Estimated time for incomplete lines: 42.39 seconds.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Finished 4 / 12 lines.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 3.58 seconds. Estimated time for incomplete lines: 28.64 seconds.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Finished 5 / 12 lines.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 2.87 seconds. Estimated time for incomplete lines: 20.09 seconds.\n",
      "2025-08-07 10:36:24 +0200   31044 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-08-07 10:36:24 +0200   31044 execution.bulk     INFO     Average execution time for completed lines: 1.32 seconds. Estimated time for incomplete lines: 1.32 seconds.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Finished 6 / 12 lines.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 2.44 seconds. Estimated time for incomplete lines: 14.64 seconds.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Finished 7 / 12 lines.\n",
      "2025-08-07 10:36:24 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 2.11 seconds. Estimated time for incomplete lines: 10.55 seconds.\n",
      "2025-08-07 10:36:25 +0200   45032 execution.bulk     INFO     Finished 8 / 12 lines.\n",
      "2025-08-07 10:36:25 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 1.95 seconds. Estimated time for incomplete lines: 7.8 seconds.\n",
      "2025-08-07 10:36:25 +0200   45032 execution.bulk     INFO     Finished 9 / 12 lines.\n",
      "2025-08-07 10:36:25 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 1.74 seconds. Estimated time for incomplete lines: 5.22 seconds.\n",
      "2025-08-07 10:36:25 +0200   45032 execution.bulk     INFO     Finished 10 / 12 lines.\n",
      "2025-08-07 10:36:25 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 1.59 seconds. Estimated time for incomplete lines: 3.18 seconds.\n",
      "2025-08-07 10:36:26 +0200   31044 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-08-07 10:36:26 +0200   31044 execution.bulk     INFO     Average execution time for completed lines: 1.37 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"task_adherence_20250807_083610_020820\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-07 08:36:10.020820+00:00\"\n",
      "Duration: \"0:00:16.861204\"\n",
      "\n",
      "2025-08-07 10:36:27 +0200   45032 execution.bulk     INFO     Finished 11 / 12 lines.\n",
      "2025-08-07 10:36:27 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 1.63 seconds. Estimated time for incomplete lines: 1.63 seconds.\n",
      "2025-08-07 10:36:29 +0200   45032 execution.bulk     INFO     Finished 12 / 12 lines.\n",
      "2025-08-07 10:36:29 +0200   45032 execution.bulk     INFO     Average execution time for completed lines: 1.62 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"tool_call_accuracy_20250807_083609_997816\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-07 08:36:09.997816+00:00\"\n",
      "Duration: \"0:00:19.807666\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"tool_call_accuracy\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:19.807666\",\n",
      "        \"completed_lines\": 12,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"intent_resolution\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:13.917811\",\n",
      "        \"completed_lines\": 12,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"task_adherence\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:16.861204\",\n",
      "        \"completed_lines\": 12,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "{'tool_call_accuracy.tool_call_accuracy': 4.5, 'tool_call_accuracy.tool_call_accuracy_threshold': 3.0, 'intent_resolution.intent_resolution': 4.5, 'intent_resolution.intent_resolution_threshold': 3.0, 'task_adherence.task_adherence': 4.666666666666667, 'task_adherence.task_adherence_threshold': 3.0, 'tool_call_accuracy.binary_aggregate': 0.83, 'intent_resolution.binary_aggregate': 0.83, 'task_adherence.binary_aggregate': 1.0}\n",
      "AI Foundry URL: https://ai.azure.com/resource/build/evaluation/eae6d233-95e9-45f8-b9ad-f58c54410606?wsid=/subscriptions/8babb7f9-50f7-498f-9e0a-8bef4389331d/resourceGroups/rg-ruplisso-3364/providers/Microsoft.CognitiveServices/accounts/projetagent-resource/projects/projetagent&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    ToolCallAccuracyEvaluator,\n",
    "    IntentResolutionEvaluator,\n",
    "    TaskAdherenceEvaluator,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "ai_project_endpoint=os.environ[\"AI_PROJECT_ENDPOINT\"]\n",
    "\n",
    "intent_resolution = IntentResolutionEvaluator(model_config=model_config)\n",
    "tool_call_accuracy = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "task_adherence = TaskAdherenceEvaluator(model_config=model_config)\n",
    "\n",
    "response = evaluate(\n",
    "    data=filename,\n",
    "    evaluation_name=\"agent demo - batch run\",\n",
    "    evaluators={\n",
    "        \"tool_call_accuracy\": tool_call_accuracy,\n",
    "        \"intent_resolution\": intent_resolution,\n",
    "        \"task_adherence\": task_adherence,\n",
    "    },\n",
    "    # optionally, log your results to your Azure AI Foundry project for rich visualization \n",
    "    azure_ai_project = ai_project_endpoint\n",
    ")\n",
    "# Inspect the average scores at a high level.\n",
    "print(response[\"metrics\"])\n",
    "\n",
    "# Use the URL to inspect the results on the UI.\n",
    "print(f'AI Foundry URL: {response.get(\"studio_url\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiops2envagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
