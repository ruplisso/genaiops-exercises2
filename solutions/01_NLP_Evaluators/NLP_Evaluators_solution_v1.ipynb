{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NLP Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BleuScoreEvaluator\n",
    "\n",
    "BLEU (Bilingual Evaluation Understudy) score is commonly used in natural language processing (NLP) and machine\n",
    "translation. It is widely used in text summarization and text generation use cases. It evaluates how closely the\n",
    "generated text matches the reference text. The BLEU score ranges from 0 to 1, with higher scores indicating\n",
    "better quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import BleuScoreEvaluator\n",
    "\n",
    "bleu = BleuScoreEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu_score': 0.22961813530951883, 'bleu_result': 'fail', 'bleu_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "result = bleu(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GleuScoreEvaluator\n",
    "\n",
    "The GLEU (Google-BLEU) score evaluator measures the similarity between generated and reference texts by\n",
    "evaluating n-gram overlap, considering both precision and recall. This balanced evaluation, designed for\n",
    "sentence-level assessment, makes it ideal for detailed analysis of translation quality. GLEU is well-suited for\n",
    "use cases such as machine translation, text summarization, and text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import GleuScoreEvaluator\n",
    "\n",
    "gleu = GleuScoreEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gleu_score': 0.4090909090909091, 'gleu_result': 'fail', 'gleu_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "result = gleu(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeteorScoreEvaluator\n",
    "\n",
    "The METEOR (Metric for Evaluation of Translation with Explicit Ordering) score grader evaluates generated text by\n",
    "comparing it to reference texts, focusing on precision, recall, and content alignment. It addresses limitations of\n",
    "other metrics like BLEU by considering synonyms, stemming, and paraphrasing. METEOR score considers synonyms and\n",
    "word stems to more accurately capture meaning and language variations. In addition to machine translation and\n",
    "text summarization, paraphrase detection is an optimal use case for the METEOR score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import MeteorScoreEvaluator\n",
    "\n",
    "meteor = MeteorScoreEvaluator(alpha=0.9, beta=3.0, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meteor_score': 0.9067055393586005, 'meteor_result': 'pass', 'meteor_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "result = meteor(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RougeScoreEvaluator\n",
    "\n",
    "ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a set of metrics used to evaluate automatic\n",
    "summarization and machine translation. It measures the overlap between generated text and reference summaries.\n",
    "ROUGE focuses on recall-oriented measures to assess how well the generated text covers the reference text. Text\n",
    "summarization and document comparison are among optimal use cases for ROUGE, particularly in scenarios where text\n",
    "coherence and relevance are critical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import RougeScoreEvaluator, RougeType\n",
    "\n",
    "rouge = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_precision': 1.0, 'rouge_recall': 1.0, 'rouge_f1_score': 1.0, 'rouge_precision_result': 'pass', 'rouge_recall_result': 'pass', 'rouge_f1_score_result': 'pass', 'rouge_precision_threshold': 0.5, 'rouge_recall_threshold': 0.5, 'rouge_f1_score_threshold': 0.5}\n"
     ]
    }
   ],
   "source": [
    "result = rouge(response=\"Tokyo is the capital of Japan.\", ground_truth=\"The capital of Japan is Tokyo.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a Dataset using Math Evaluators\n",
    "\n",
    "The code below uses the Evaluate API with BLEU, GLEU, METEOR, and ROUGE evaluators to evaluate the results on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-07 13:52:26 +0200   25880 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-08-07 13:52:26 +0200   25880 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"rouge_20250807_115226_287806\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-07 11:52:26.287806+00:00\"\n",
      "Duration: \"0:00:01.003112\"\n",
      "\n",
      "2025-08-07 13:52:34 +0200   15200 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-08-07 13:52:34 +0200   15200 execution.bulk     INFO     Average execution time for completed lines: 0.17 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"gleu_20250807_115226_312344\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-07 11:52:26.312344+00:00\"\n",
      "Duration: \"0:00:08.571440\"\n",
      "\n",
      "2025-08-07 13:52:35 +0200    5060 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-08-07 13:52:35 +0200    5060 execution.bulk     INFO     Average execution time for completed lines: 0.18 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"bleu_20250807_115226_279723\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-07 11:52:26.279723+00:00\"\n",
      "Duration: \"0:00:08.963219\"\n",
      "\n",
      "2025-08-07 13:52:35 +0200   30396 execution.bulk     INFO     Finished 50 / 50 lines.\n",
      "2025-08-07 13:52:35 +0200   30396 execution.bulk     INFO     Average execution time for completed lines: 0.18 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"meteor_20250807_115226_299815\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-08-07 11:52:26.299815+00:00\"\n",
      "Duration: \"0:00:09.254112\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"bleu\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:08.963219\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"gleu\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:08.571440\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"meteor\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:09.254112\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"rouge\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:01.003112\",\n",
      "        \"completed_lines\": 50,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "AI Foundry URL: https://ai.azure.com/resource/build/evaluation/86d1f5ff-a164-41d5-b583-905d1e7c5339?wsid=/subscriptions/8babb7f9-50f7-498f-9e0a-8bef4389331d/resourceGroups/rg-ruplisso-3364/providers/Microsoft.CognitiveServices/accounts/projetagent-resource/projects/projetagent&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': {'bleu.binary_aggregate': 0.06,\n",
      "             'bleu.bleu_score': 0.2725492373855213,\n",
      "             'bleu.bleu_threshold': 0.5,\n",
      "             'gleu.binary_aggregate': 0.34,\n",
      "             'gleu.gleu_score': 0.407072927072927,\n",
      "             'gleu.gleu_threshold': 0.5,\n",
      "             'meteor.binary_aggregate': 1.0,\n",
      "             'meteor.meteor_score': 0.8376872508938054,\n",
      "             'meteor.meteor_threshold': 0.5,\n",
      "             'rouge.binary_aggregate': 0.96,\n",
      "             'rouge.rouge_f1_score': 0.6787035187035185,\n",
      "             'rouge.rouge_f1_score_threshold': 0.5,\n",
      "             'rouge.rouge_precision': 0.6612857142857144,\n",
      "             'rouge.rouge_precision_threshold': 0.5,\n",
      "             'rouge.rouge_recall': 0.7116190476190476,\n",
      "             'rouge.rouge_recall_threshold': 0.5},\n",
      " 'rows': [{'inputs.ground_truth': 'A dog is barking loudly.',\n",
      "           'inputs.response': 'The dog barks loudly.',\n",
      "           'line_number': 0,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.1098261401671543,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2222222222222222,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.635593220338983,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.4444444444444445,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'fail',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.4,\n",
      "           'outputs.rouge.rouge_recall_result': 'fail',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They visited the beach.',\n",
      "           'inputs.response': 'They went to the beach.',\n",
      "           'line_number': 1,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7352941176470589,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The sun shines brightly.',\n",
      "           'inputs.response': 'The sun is shining brightly.',\n",
      "           'line_number': 2,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.1374292659508281,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3333333333333333,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She prepared a tasty meal.',\n",
      "           'inputs.response': 'She cooked a delicious meal.',\n",
      "           'line_number': 3,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.11556377708900069,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2777777777777778,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.5260416666666666,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He reads the paper each morning.',\n",
      "           'inputs.response': 'He reads the newspaper every morning.',\n",
      "           'line_number': 4,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.24279161784109232,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.4090909090909091,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.6914285714285714,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'Kids are playing in the park.',\n",
      "           'inputs.response': 'The children are playing in the park.',\n",
      "           'line_number': 5,\n",
      "           'outputs.bleu.bleu_result': 'pass',\n",
      "           'outputs.bleu.bleu_score': 0.6803749333171202,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.6923076923076923,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9844782983615982,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7692307692307692,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.7142857142857143,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8333333333333334,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The car is parked outside the house.',\n",
      "           'inputs.response': 'The car is parked outside.',\n",
      "           'line_number': 6,\n",
      "           'outputs.bleu.bleu_result': 'pass',\n",
      "           'outputs.bleu.bleu_score': 0.5698363775444273,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5769230769230769,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7211538461538461,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8333333333333333,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.7142857142857143,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She writes a letter.',\n",
      "           'inputs.response': 'She is writing a letter.',\n",
      "           'line_number': 7,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He watches a film.',\n",
      "           'inputs.response': 'He is watching a movie.',\n",
      "           'line_number': 8,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.049475702907177795,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.16666666666666666,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.618872549019608,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.4444444444444445,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'fail',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.4,\n",
      "           'outputs.rouge.rouge_precision_result': 'fail',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.5,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'Flowers are in bloom.',\n",
      "           'inputs.response': 'The flowers are blooming.',\n",
      "           'line_number': 9,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.05428693985879238,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.14285714285714285,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7500000000000001,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.5,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They are enjoying a picnic.',\n",
      "           'inputs.response': 'They are having a picnic.',\n",
      "           'line_number': 10,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.293945703509473,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.8066666666666668,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8000000000000002,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.8,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'A baby is asleep.',\n",
      "           'inputs.response': 'The baby is sleeping.',\n",
      "           'line_number': 11,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.5111111111111111,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.5,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She paints a picture.',\n",
      "           'inputs.response': 'She is painting a picture.',\n",
      "           'line_number': 12,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He repairs the bike.',\n",
      "           'inputs.response': 'He is fixing the bike.',\n",
      "           'line_number': 13,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'A book is on the table.',\n",
      "           'inputs.response': 'The book is on the table.',\n",
      "           'line_number': 14,\n",
      "           'outputs.bleu.bleu_result': 'pass',\n",
      "           'outputs.bleu.bleu_score': 0.8091067115702212,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.8181818181818182,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.8551587301587302,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8333333333333334,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.8333333333333334,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8333333333333334,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They dance together.',\n",
      "           'inputs.response': 'They are dancing together.',\n",
      "           'line_number': 15,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9146341463414633,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714285715,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The coffee is very hot.',\n",
      "           'inputs.response': 'The coffee is hot.',\n",
      "           'line_number': 16,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.30834517982041937,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.8203389830508474,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.888888888888889,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She learns to swim.',\n",
      "           'inputs.response': 'She is learning to swim.',\n",
      "           'line_number': 17,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He plays the guitar.',\n",
      "           'inputs.response': 'He is playing the guitar.',\n",
      "           'line_number': 18,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The sky is clear and blue.',\n",
      "           'inputs.response': 'The sky is clear.',\n",
      "           'line_number': 19,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.47398785011707933,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.711764705882353,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They build a sandcastle.',\n",
      "           'inputs.response': 'They are building a sandcastle.',\n",
      "           'line_number': 20,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The pizza is done.',\n",
      "           'inputs.response': 'The pizza is ready.',\n",
      "           'line_number': 21,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.32184424080043433,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7500000000000001,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She reads a novel.',\n",
      "           'inputs.response': 'She is reading a novel.',\n",
      "           'line_number': 22,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He drives a car.',\n",
      "           'inputs.response': 'He is driving a car.',\n",
      "           'line_number': 23,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The water is chilly.',\n",
      "           'inputs.response': 'The water is cold.',\n",
      "           'line_number': 24,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.32184424080043433,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7500000000000001,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They sing a song.',\n",
      "           'inputs.response': 'They are singing a song.',\n",
      "           'line_number': 25,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The cake tastes great.',\n",
      "           'inputs.response': 'The cake is delicious.',\n",
      "           'line_number': 26,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.5111111111111111,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.5,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She knits a scarf.',\n",
      "           'inputs.response': 'She is knitting a scarf.',\n",
      "           'line_number': 27,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He jogs in the park.',\n",
      "           'inputs.response': 'He is jogging in the park.',\n",
      "           'line_number': 28,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.4347208719449914,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9653916211293262,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7272727272727272,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The room is tidy.',\n",
      "           'inputs.response': 'The room is clean.',\n",
      "           'line_number': 29,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.32184424080043433,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7500000000000001,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They watch the sunset.',\n",
      "           'inputs.response': 'They are watching the sunset.',\n",
      "           'line_number': 30,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The soup is steaming.',\n",
      "           'inputs.response': 'The soup is hot.',\n",
      "           'line_number': 31,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.32184424080043433,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7500000000000001,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She plants flowers.',\n",
      "           'inputs.response': 'She is planting flowers.',\n",
      "           'line_number': 32,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9146341463414633,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714285715,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He reads a magazine.',\n",
      "           'inputs.response': 'He is reading a magazine.',\n",
      "           'line_number': 33,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The ice cream melts.',\n",
      "           'inputs.response': 'The ice cream is melting.',\n",
      "           'line_number': 34,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They play chess.',\n",
      "           'inputs.response': 'They are playing chess.',\n",
      "           'line_number': 35,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9146341463414633,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714285715,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The bread is freshly baked.',\n",
      "           'inputs.response': 'The bread is fresh.',\n",
      "           'line_number': 36,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.26350377764435096,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.635593220338983,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She sews a dress.',\n",
      "           'inputs.response': 'She is sewing a dress.',\n",
      "           'line_number': 37,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He fishes at the lake.',\n",
      "           'inputs.response': 'He is fishing at the lake.',\n",
      "           'line_number': 38,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.4347208719449914,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9653916211293262,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7272727272727272,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The tea is warm and soothing.',\n",
      "           'inputs.response': 'The tea is warm.',\n",
      "           'line_number': 39,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.47398785011707933,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.711764705882353,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.8,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They hike in the mountains.',\n",
      "           'inputs.response': 'They are hiking in the mountains.',\n",
      "           'line_number': 40,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.4347208719449914,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9653916211293262,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.7272727272727272,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The music is very loud.',\n",
      "           'inputs.response': 'The music is loud.',\n",
      "           'line_number': 41,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.30834517982041937,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.8203389830508474,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.888888888888889,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She bakes cookies.',\n",
      "           'inputs.response': 'She is baking cookies.',\n",
      "           'line_number': 42,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9146341463414633,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714285715,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He plays basketball.',\n",
      "           'inputs.response': 'He is playing basketball.',\n",
      "           'line_number': 43,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9146341463414633,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714285715,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The wind is very strong.',\n",
      "           'inputs.response': 'The wind is strong.',\n",
      "           'line_number': 44,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.30834517982041937,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.8203389830508474,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.888888888888889,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 1.0,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.8,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'They study for exams.',\n",
      "           'inputs.response': 'They are studying for exams.',\n",
      "           'line_number': 45,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The film is interesting.',\n",
      "           'inputs.response': 'The movie is interesting.',\n",
      "           'line_number': 46,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.32184424080043433,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'pass',\n",
      "           'outputs.gleu.gleu_score': 0.5,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7500000000000001,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'She practices yoga.',\n",
      "           'inputs.response': 'She is practicing yoga.',\n",
      "           'line_number': 47,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.13414195051824768,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.2857142857142857,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9146341463414633,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.5714285714285715,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.5,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.6666666666666666,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'He writes a report.',\n",
      "           'inputs.response': 'He is writing a report.',\n",
      "           'line_number': 48,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.25119835939119545,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.3888888888888889,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.9490196078431373,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.6666666666666665,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.6,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5},\n",
      "          {'inputs.ground_truth': 'The garden looks beautiful.',\n",
      "           'inputs.response': 'The garden is beautiful.',\n",
      "           'line_number': 49,\n",
      "           'outputs.bleu.bleu_result': 'fail',\n",
      "           'outputs.bleu.bleu_score': 0.17141814854755813,\n",
      "           'outputs.bleu.bleu_threshold': 0.5,\n",
      "           'outputs.gleu.gleu_result': 'fail',\n",
      "           'outputs.gleu.gleu_score': 0.42857142857142855,\n",
      "           'outputs.gleu.gleu_threshold': 0.5,\n",
      "           'outputs.meteor.meteor_result': 'pass',\n",
      "           'outputs.meteor.meteor_score': 0.7500000000000001,\n",
      "           'outputs.meteor.meteor_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_f1_score': 0.75,\n",
      "           'outputs.rouge.rouge_f1_score_result': 'pass',\n",
      "           'outputs.rouge.rouge_f1_score_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_precision': 0.75,\n",
      "           'outputs.rouge.rouge_precision_result': 'pass',\n",
      "           'outputs.rouge.rouge_precision_threshold': 0.5,\n",
      "           'outputs.rouge.rouge_recall': 0.75,\n",
      "           'outputs.rouge.rouge_recall_result': 'pass',\n",
      "           'outputs.rouge.rouge_recall_threshold': 0.5}],\n",
      " 'studio_url': 'https://ai.azure.com/resource/build/evaluation/86d1f5ff-a164-41d5-b583-905d1e7c5339?wsid=/subscriptions/8babb7f9-50f7-498f-9e0a-8bef4389331d/resourceGroups/rg-ruplisso-3364/providers/Microsoft.CognitiveServices/accounts/projetagent-resource/projects/projetagent&tid=16b3c013-d300-468d-ac64-7eda0820b6d3'}\n",
      "AI Foundry URL: https://ai.azure.com/resource/build/evaluation/86d1f5ff-a164-41d5-b583-905d1e7c5339?wsid=/subscriptions/8babb7f9-50f7-498f-9e0a-8bef4389331d/resourceGroups/rg-ruplisso-3364/providers/Microsoft.CognitiveServices/accounts/projetagent-resource/projects/projetagent&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "ai_project_endpoint=os.environ[\"AI_PROJECT_ENDPOINT\"]\n",
    "\n",
    "result = evaluate(\n",
    "        evaluation_name=\"NLP Evaluators\",\n",
    "        data=\"data.jsonl\",\n",
    "        evaluators={\n",
    "            \"bleu\": bleu,\n",
    "            \"gleu\": gleu,\n",
    "            \"meteor\": meteor,\n",
    "            \"rouge\": rouge,\n",
    "        },\n",
    "        azure_ai_project = ai_project_endpoint,\n",
    "    )\n",
    "\n",
    "print(f'AI Foundry URL: {result.get(\"studio_url\")}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the foundry URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'AI Foundry URL: {result.get(\"studio_url\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiops2envagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
