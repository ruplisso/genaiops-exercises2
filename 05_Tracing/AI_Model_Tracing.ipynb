{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a4f240",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Goal of the Exercise  \n",
    "\n",
    "In this exercise, you'll learn how to implement **AI model tracing** using **OpenTelemetry** and the Azure AI Inference library. You'll specifically focus on tracing interactions with Azure AI models, including the use of custom functions within AI workflows.\n",
    "\n",
    "Through this hands-on experience, you'll:\n",
    "\n",
    "- Set up and configure OpenTelemetry tracing.\n",
    "- Implement traced functions that integrate external data sources with AI models.\n",
    "- Utilize tracing to monitor, debug, and optimize AI model interactions and function calls.\n",
    "- Understand best practices for instrumenting AI applications for better observability and performance analysis.\n",
    "\n",
    "By completing these tasks, you'll gain essential skills for effectively tracing and troubleshooting AI models in production environments, enhancing transparency and performance.\n",
    "\n",
    "### Links to documentation\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-application\n",
    "\n",
    "https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-agents/samples/agents_telemetry/sample_agents_basics_with_azure_monitor_tracing.py\n",
    "\n",
    "\n",
    "The two lib used for tracing (they should be already available in your environment)\n",
    "\n",
    "- azure-ai-inference[opentelemetry]\n",
    "\n",
    "https://pypi.org/project/azure-ai-inference/\n",
    "\n",
    "- azure-monitor-opentelemetry\n",
    "\n",
    "https://pypi.org/project/azure-monitor-opentelemetry/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8149f263",
   "metadata": {},
   "source": [
    "### ðŸ”§ Task: Configure Azure AI Inference Client\n",
    "Fill in the code to configure the Azure AI Inference client properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfbe322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure Azure AI Inference client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97c399",
   "metadata": {},
   "source": [
    "## Defining Functions with Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70369b8c",
   "metadata": {},
   "source": [
    "### ðŸ”§ Task: Define a Function with Tracing\n",
    "- Use OpenTelemetry's tracer to instrument the `get_temperature` and the 'get_weather' functions.\n",
    "- Those functions should call an external API (e.g., weather API) and log the tracing span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement function with tracing\n",
    "\n",
    "import requests\n",
    "from opentelemetry.trace import get_tracer\n",
    "\n",
    "tracer = get_tracer(__name__)\n",
    "\n",
    "weather_api_key = os.environ.get(\"WEATHER_API_KEY\")\n",
    "\n",
    "@tracer.start_as_current_span(\"get_temperature\") \n",
    "def get_temperature(city: str) -> str:\n",
    "\n",
    "# TODO: To be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36223ee2",
   "metadata": {},
   "source": [
    "## Chat Completion with Function Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8021b77",
   "metadata": {},
   "source": [
    "### ðŸ”§ Task: Configure Azure AI Inference Client\n",
    "Fill in the code to configure the Azure AI Inference client properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71aa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure Azure AI Inference client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6ef8f",
   "metadata": {},
   "source": [
    "## Running the AI Model and Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc64dcd",
   "metadata": {},
   "source": [
    "### ðŸ”§ Task: Implement Chat Completion with Function Calls\n",
    "- Complete the implementation of the chat completion.\n",
    "- Define appropriate tool definitions and enable the AI model to invoke traced functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7650f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement chat completion with function calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
